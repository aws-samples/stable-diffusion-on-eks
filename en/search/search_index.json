{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Stable Diffusion on EKS","text":"<p>Implementing a fast scaling and low cost Stable Diffusion inference solution with serverless and containers on AWS</p> <p>Stable Diffusion is a popular open source project for generating images using Gen AI. Building a scalable and cost efficient inference solution is a common challenge AWS customers facing. This project shows how to use serverless and container services to build an end-to-end low cost and fast scaling asyncronous image generation architecture. This repo contains the sample code and CDK deployment scripts, helping you to deploy this solution in a few steps.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Asyncronous API and Serverless Event-Driven Architecture</li> <li>Image Generation with Stable Diffusion Web UI on Amazon EKS</li> <li>Automatic queue length based scaling with KEDA</li> <li>Automatic provisioning ec2 instances with Karpenter</li> <li>Scaling up new inference nodes within 2 minutes</li> <li>Saving up to 70% with GPU spot instances</li> </ul> <p>Disclaimer</p> <p>This solution is provided solely as a reference architecture and example code, offered to you under the MIT-0 License.</p> <p>This solution is intended for demonstration, proof of concept, or learning purposes only. You should not deploy this solution directly in your production account or use it for production or other critical data.</p> <p>Deploying this solution may result in AWS charges due to the creation or use of chargeable AWS resources (such as running Amazon EC2 instances or using Amazon S3 storage).</p>"},{"location":"implementation-guide/faq/","title":"Frequently Asked Questions","text":""},{"location":"implementation-guide/faq/#general-questions","title":"General Questions","text":"<ul> <li> <p>What is the Stable Diffusion on Amazon EKS solution?</p> <p>The Stable Diffusion on Amazon EKS solution is a reference architecture for deploying Stable Diffusion on Amazon Web Services. This reference architecture is designed based on an event-driven architecture and leverages modern application services such as serverless and containers. With this solution, users can quickly deploy Stable Diffusion for inferencing and generating images on Amazon Web Services, meeting requirements for rapid on-demand scaling, high availability, and cost-effectiveness.</p> </li> <li> <p>What makes this solution unique?</p> <p>The Stable Diffusion on Amazon EKS solution is designed based on an event-driven architecture, utilizing KEDA for automatic scaling based on queue length. It can effectively handle high-concurrency inference requests and, with the help of Karpenter and Bottlerocket, rapidly scale new inference nodes, greatly reducing image generation wait times. Additionally, the solution supports the use of GPU Spot instances, enabling customers to utilize the required computing resources at a lower cost. The solution also supports multiple community Stable Diffusion runtimes and provides unified management through the Kubernetes API for underlying Amazon EKS, offering openness and flexibility. Customers can easily customize this reference architecture to meet their specific business requirements.</p> </li> <li> <p>When is it more suitable for me to use Stable Diffusion on Amazon EKS?</p> <p>Compared to other solutions using Stable Diffusion on Amazon Web Services, this solution is more suitable for business workloads with high concurrent requests or fluctuating demands, where low-latency image generation performance is crucial. Alternatively, for customers already using the Kubernetes technology stack as a resource scheduling and management platform or for customers with more customization requirements, this solution can provide additional benefits.</p> </li> <li> <p>What AWS services does this solution use?</p> <p>Please refer to the AWS Services page.</p> </li> <li> <p>How does AWS support this solution?</p> <p>This solution is provided by the AWS Solutions Architecture team under the MIT-0 license. The solution currently only receives community support. If you encounter bugs in the solution code or have feature suggestions, please contact us through GitHub.</p> <p>If there are issues with AWS products or services mentioned in the solution, you can contact AWS support based on your support plan.</p> <p>The AWS Solutions Architecture team can provide solution discussions, workshops, and deployment support. If you need assistance, please contact your customer team or contact us through this webpage.</p> </li> <li> <p>How do I deploy this solution?</p> <p>We provide a one-click deployment template based on AWS CDK, allowing you to deploy this solution in your AWS account. You can customize the deployment through various configuration options in the configuration file. After deployment, you can further extend the solution.</p> </li> <li> <p>Which instance types can I use?</p> <p>Currently, you can use accelerated computing instances in the corresponding region. Instances such as g5, g4dn, and p3 have been tested and are supported. g3 instances are not supported due to driver issues. inf series instances are not supported at this time. CPU instance types generate images more slowly and are not recommended for use.</p> </li> </ul>"},{"location":"implementation-guide/release-notes/","title":"Release note","text":"Date Update Description October 2023 Initial release"},{"location":"implementation-guide/uninstall/","title":"Delete Solution","text":"<p>The deployed solution can be deleted using CloudFormation.</p> <p>Permanent Deletion</p> <p>All deleted resources will be permanently removed and cannot be recovered by any means.</p>"},{"location":"implementation-guide/uninstall/#deletion-scope","title":"Deletion Scope","text":"<ul> <li> <p>The following will be permanently deleted:</p> <ul> <li>Amazon EKS cluster and all worker nodes</li> <li>SNS topics and all subscriptions</li> <li>SQS queues</li> <li>VPC</li> <li>IAM roles used by the solution</li> </ul> </li> <li> <p>The following will not be deleted:</p> <ul> <li>S3 bucket storing output images</li> <li>S3 bucket storing models</li> </ul> </li> </ul>"},{"location":"implementation-guide/uninstall/#pre-deletion-preparation","title":"Pre-Deletion Preparation","text":"<p>Before deleting the solution, ensure the following conditions are met:</p> <ul> <li>All SQS queues have been emptied.</li> <li>No additional policies are attached to IAM roles.</li> <li>No additional resources (such as EC2 instances, ENIs, Cloud9 environments, etc.) exist within the VPC.</li> </ul>"},{"location":"implementation-guide/uninstall/#deleting-the-solution","title":"Deleting the Solution","text":"<p>You can delete the solution using either the CDK CLI or the AWS Management Console.</p> AWS Management ConsoleAWS CDK <ul> <li>Navigate to the AWS CloudFormation console</li> <li>Select Stacks</li> <li>In the list, select SdOnEKSStack (or the name you customized)</li> <li>Select Delete, and in the pop-up dialog, choose Delete</li> </ul> <p>In the solution's source code directory, run the following command to delete the solution:</p> <pre><code>npx cdk destroy\n</code></pre> <p>Deleting the solution takes approximately 20-30 minutes.</p>"},{"location":"implementation-guide/architecture/architecture/","title":"Architecture Overview","text":""},{"location":"implementation-guide/architecture/architecture/#architecture-diagram","title":"Architecture Diagram","text":""},{"location":"implementation-guide/architecture/architecture/#components","title":"Components","text":"<p>This solution has 3 main components:</p> <ul> <li>Serverless task scheduling and dispatching</li> <li>Stable Diffusion runtime based on Amazon EKS and Amazon EC2</li> <li>Management and maintenance components</li> </ul>"},{"location":"implementation-guide/architecture/architecture/#task-scheduling-and-dispatching","title":"Task Scheduling and Dispatching","text":"<p>This component has an API endpoint based on Amazon API Gateway. It also has a task dispatching part based on Amazon SNS and Amazon SQS.</p> <ul> <li>The user sends requests (model, prompt, etc.) to the API endpoint provided by Amazon API Gateway.</li> <li>Requests are validated by Amazon Lambda and sent to an Amazon SNS topic.</li> <li>Amazon SNS sends the requests to the corresponding runtime's SQS queue based on the runtime name in the request.</li> </ul>"},{"location":"implementation-guide/architecture/architecture/#stable-diffusion-runtime","title":"Stable Diffusion Runtime","text":"<p>This component is a Stable Diffusion runtime based on Amazon EKS. It can scale elastically based on requests.</p> <p>For each runtime:</p> <ul> <li>During deployment, each runtime has its own Amazon SQS queue to receive requests.</li> <li>The Queue Agent receives tasks from the SQS queue and sends them to the Stable Diffusion runtime to generate images.</li> <li>The generated images are stored in an Amazon S3 bucket by the Queue Agent. A completion notification is sent to an Amazon SNS topic.</li> <li>When there are too many messages in the SQS queue, KEDA increases the number of runtime replicas based on the queue length. Karpenter starts new GPU instances to host the new replicas.</li> <li>When there are no more messages queued, KEDA reduces the number of replicas. Karpenter shuts down unnecessary GPU instances to save costs.</li> </ul>"},{"location":"implementation-guide/architecture/architecture/#management-and-maintenance","title":"Management and Maintenance","text":"<p>This solution provides complete observability and management components:</p> <ul> <li>Metrics monitoring and logging based on CloudWatch</li> <li>End-to-end tracing based on AWS X-Ray</li> <li>Infrastructure as code deployment using AWS CDK</li> </ul>"},{"location":"implementation-guide/architecture/services-in-this-solution/","title":"AWS Services in the solution","text":"<p>The following AWS services are included in this solution:</p> AWS Service Description Amazon S3 Used for storing models and generated images. Amazon ECR Used for storing container images required by the runtime. Amazon API Gateway Used to provide an API interface for external access. AWS Lambda Used for request validation and routing. Amazon SQS Used to store pending tasks for processing. Amazon SNS Used to route tasks to different SQS queues and provide notifications and callbacks after processing is complete. Amazon EKS Used for managing and running the Stable Diffusion runtime. Amazon EC2 Used for running the Stable Diffusion runtime. Amazon CloudWatch Used for monitoring the system's operation, providing numerical monitoring, logs, and tracing. AWS CDK Used for deploying and updating this solution."},{"location":"implementation-guide/deployment/","title":"Overview","text":"<p>Before deploying the solution, it is recommended to review information about the architecture diagram and regional support in this guide. Then follow the instructions below to configure and deploy the solution to your account.</p>"},{"location":"implementation-guide/deployment/#prerequisites","title":"Prerequisites","text":"<p>Check if all considerations are met according to the deployment planning document.</p>"},{"location":"implementation-guide/deployment/#deployment-steps","title":"Deployment Steps","text":"<p>We provide a one-click deployment script for quick start. Total deployment time is around 30 minutes.</p>"},{"location":"implementation-guide/deployment/#get-source-code","title":"Get Source Code","text":"<p>Run the following command to get the source code and deployment scripts:</p> <pre><code>git clone --recursive https://github.com/aws-samples/stable-diffusion-on-eks\ncd stable-diffusion-on-eks\n</code></pre>"},{"location":"implementation-guide/deployment/#one-click-deploy","title":"One-Click Deploy","text":"<p>Run the following command to quickly deploy with minimal settings:</p> <pre><code>cd deploy\n./deploy.sh\n</code></pre> <p>The script will:</p> <ul> <li>Install required runtimes and tools</li> <li>Create an S3 bucket, download Stable Diffusion 1.5 base model from HuggingFace and place it in the bucket</li> <li>Create an EBS snapshot containing the SD Web UI image using our sample image</li> <li>Create a Stable Diffusion solution with SD Web UI runtime</li> </ul>"},{"location":"implementation-guide/deployment/#deployment-parameters","title":"Deployment Parameters","text":"<p>The script provides some parameters for you to customize the deployed solution:</p> <ul> <li><code>-h, --help</code>: Show help information</li> <li><code>-n, --stack-name</code>: Customize solution name, affecting generated resource names. Default is <code>sdoneks</code>.</li> <li><code>-R, --region</code>: Region to deploy the solution. Defaults to current AWS profile region.</li> <li><code>-d, --dry-run</code>: Only generate config files, do not deploy.</li> <li><code>-b, --bucket</code>: Specify existing S3 bucket name to store models. The bucket must exist and be in same region as solution. You can manually create the S3 bucket following this doc.</li> <li><code>-s, --snapshot</code>: Specify existing EBS snapshot ID. You can build the EBS snapshot yourself following this doc.</li> <li><code>-r, --runtime-name</code>: Specify deployed runtime name, affecting name used in API calls. Default is <code>sdruntime</code>.</li> <li><code>-t, --runtime-type</code>: Specify deployed runtime type, only accepts <code>sdwebui</code> and <code>comfyui</code>. Default is <code>sdwebui</code>.</li> </ul> <p>If you need to deploy multiple runtimes, or have other parameter requirements (like custom image), you can first use <code>--dry-run</code> to generate base config files by the script, then modify them.</p>"},{"location":"implementation-guide/deployment/#manual-deployment","title":"Manual Deployment","text":"<p>You can also manually deploy this solution on AWS without using the script by following these steps:</p> <ol> <li>Create Amazon S3 model bucket and store required models in the bucket</li> <li>(Optional) Build container image</li> <li>(Optional) Store container image in EBS cache to accelerate startup</li> <li>Deploy and launch the solution stack</li> </ol>"},{"location":"implementation-guide/deployment/configuration/","title":"Configuration","text":""},{"location":"implementation-guide/deployment/configuration/#infrastructure","title":"Infrastructure","text":"<p>We use config file to customize infrastructure and runtime. By default, the config file name is <code>config.yaml</code>. You can use alternative config file by changing environment variable <code>CDK_CONFIG_PATH</code>.</p> <p>The following table lists the configurable parameters of CDK template and the default values.</p> Parameter Description Required Default <code>stackName</code> Name of the stack. The name will be added as a prefix of all resource name. Yes <code>SdOnEKS</code> <code>modelBucketArn</code> S3 bucket for model storage. Models file should be manual populated into the bucket. This parameter applies to all runtimes. Yes <code>\"\"</code> <code>modelsRuntime</code> Define Stable diffusion runtime. At least one runtime should be defined. Yes <code>- name: \"sdruntime\"  modelFilename: \"v1-5-pruned-emaonly.ckpt\"</code> <code>modelsRuntime.name</code> Name of individual Stable diffusion runtime. Yes <code>sdruntime</code> <code>modelsRuntime.namespace</code> Namespace of individual Stable diffusion runtime. Yes <code>default</code> <code>modelsRuntime.chartRepository</code> Override default helm chart repository. Protocol (<code>oci://</code> or <code>https://</code>)should be added as a prefix of repository. (Default: <code>https://aws-samples.github.io/stable-diffusion-on-eks</code>) No N/A <code>modelsRuntime.chartVersion</code> Override version of helm chart. (Default: 0.1.0) No N/A <code>modelsRuntime.modelFilename</code> File of model using in the runtime. Filename should be in <code>.ckpt</code> or <code>.safetensors</code> format. Filename should be quoted if contains number only. Yes <code>v1-5-pruned-emaonly.safetensors</code> <code>modelsRuntime.extraValues</code> Extra parameter passed to the runtime. See values definition for detail. No N/A <code>dynamicModelRuntime.enabled</code> Generate a runtime which allows models be switched by request. See multi model support for detail. Yes <code>false</code> <code>dynamicModelRuntime.namespace</code> Namespace of dynamic model runtime. Required if <code>dynamicModelRuntime.enabled</code> is <code>true</code>. No <code>default</code> <code>dynamicModelRuntime.chartRepository</code> Override default helm chart repository. (Default: <code>https://aws-samples.github.io/stable-diffusion-on-eks</code>) No N/A <code>dynamicModelRuntime.chartVersion</code> Override version of helm chart. (Default: 0.1.0) No N/A <code>dynamicModelRuntime.extraValues</code> Extra parameter passed to the runtime. See values definition for detail. No N/A"},{"location":"implementation-guide/deployment/configuration/#application-helm-chart","title":"Application (Helm Chart)","text":"<p>Stable diffusion runtime are deployed via helm chart. You can customize individual stable diffusion runtime by passing values via <code>modelsRuntime.extraValues</code>.</p> <p>The following table lists the configurable parameters of helm chart and the default values. All values are not mandatory. Please some value will be populated by CDK, and not changeable by user.</p> Parameter Description Default Global <code>global.awsRegion</code> AWS region where the stack resides. Not changable. Populated by CDK <code>global.stackName</code> Name of CDK stack. Not changable. Populated by CDK Karpenter Provisioner <code>karpenter.provisioner.labels</code> Labels applied to all nodes. Should be in key-values format. <code>{}</code> <code>karpenter.provisioner.capacityType.onDemand</code> Allow Karpenter to launch on-demand node. <code>true</code> <code>karpenter.provisioner.capacityType.spot</code> Allow Karpenter to create spot node. When <code>provisioner.capacityType.onDemand</code> is true, Karpenter will priortize launching Spot instance. <code>true</code> <code>karpenter.provisioner.instanceType</code> An array of instance types Karpenter can launch. Should only include instance type available in current region. <code>- \"g5.xlarge\"</code> <code>karpenter.provisioner.extraRequirements</code> Additional requirement for Karpenter to choose instance type. <code>[]</code> <code>karpenter.provisioner.extraTaints</code> Provisioned nodes will have <code>nvidia.com/gpu:NoSchedule</code> and <code>runtime:NoSchedule</code> taints by default. Use this paremeter for additional taints. <code>[]</code> <code>karpenter.provisioner.resourceLimits</code> Resource limits prevent Karpenter from creating new instances once the limit is exceeded. <code>cpu</code>, <code>memory</code> and <code>nvidia.com/gpu</code> are supported. <code>nvidia.com/gpu: 100</code> <code>karpenter.provisioner.consolidation</code> Enables consolidation which attempts to removing un-needed nodes and down-sizing those that can't be removed. <code>true</code> Karpenter Node Template <code>karpenter.nodeTemplate.securityGroupSelector</code> Tagged security groups will be attached to instances. Not changable. Populated by CDK <code>karpenter.nodeTemplate.subnetSelector</code> Instances will be launched in tagged subnets. Not changable. Populated by CDK <code>karpenter.nodeTemplate.tags</code> Tags applied to all nodes. Should be in key-values format. <code>{}</code> <code>karpenter.nodeTemplate.amiFamily</code> OS option for worker nodes. Karpenter will automatically query for the appropriate EKS optimized AMI via AWS Systems Manager (SSM). <code>AL2</code> and <code>Bottlerocket</code> are supported. <code>Bottlerocket</code> <code>karpenter.nodeTemplate.osVolume</code> Control the Elastic Block Storage (EBS) volumes that Karpenter attaches to provisioned nodes. See this for schema. This volume will be attached to <code>/dev/xvda</code>. <code>karpenter.nodeTemplate.dataVolume</code> Control the Elastic Block Storage (EBS) volumes that Karpenter attaches to provisioned nodes. See this for schema. This volume will be attached to <code>/dev/xvdb</code>. Required when using <code>Bottlerocket</code>. <code>karpenter.nodeTemplate.userData</code> UserData that is applied to your worker nodes. See the examples here for format. <code>\"\"</code> runtime <code>runtime.labels</code> Labels applied to all resources. Should be in key-values format. <code>\"\"</code> <code>runtime.annotations</code> Annotations applied to stable diffusion runtime. Should be in key-values format. <code>\"\"</code> <code>runtime.serviceAccountName</code> Name of service account used by runtime. Not changable. Populated by CDK <code>runtime.replicas</code> Replica count of runtime. <code>1</code> <code>runtime.scaling.enabled</code> Enable auto scaling by SQS length. <code>true</code> <code>runtime.scaling.queueLength</code> Target value for queue length. KEDA will scale pod to <code>ApproximateNumberOfMessage / queueLength</code> replicas. <code>10</code> <code>runtime.scaling.cooldownPeriod</code> The period (in seconds) to wait after the last trigger reported active before scaling the resource back to <code>minReplicaCount</code>. <code>60</code> <code>runtime.scaling.maxReplicaCount</code> This setting is passed to the HPA definition that KEDA will create for a given resource and holds the maximum number of replicas of the target resource. <code>20</code> <code>runtime.scaling.minReplicaCount</code> Minimum number of replicas KEDA will scale the resource down to. <code>0</code> <code>runtime.scaling.pollingInterval</code> Interval (in seconds) to check each trigger on. <code>1</code> <code>runtime.scaling.scaleOnInFlight</code> When set to <code>true</code>, not visible (in-flight) messages will be counted in <code>ApproximateNumberOfMessage</code> <code>false</code> <code>runtime.scaling.extraHPAConfig</code> KEDA would feed values from this section directly to the HPA\u2019s <code>behavior</code> field. Follow Kubernetes documentation for details. <code>{}</code> Stable Diffusion Runtime <code>runtime.inferenceApi.image.repository</code> Image Repository of Runtime. <code>sdoneks/inference-api</code> <code>runtime.inferenceApi.image.tag</code> Image tag of Runtime. <code>latest</code> <code>runtime.inferenceApi.modelFilename</code> Model filename of Runtime. Not changable. Populated by CDK <code>runtime.inferenceApi.extraEnv</code> Extra environment variable for Runtime. Should be in Kubernetes format. <code>{}</code> <code>runtime.inferenceApi.resources</code> Resource request and limit for Runtime. Queue Agent <code>runtime.queueAgent.image.repository</code> Image Repository of queue agent. <code>sdoneks/queue-agent</code> <code>runtime.queueAgent.image.tag</code> Image tag of queue agent. <code>latest</code> <code>runtime.queueAgent.extraEnv</code> Extra environment variable for queue agent. Should be in Kubernetes format. <code>{}</code> <code>runtime.queueAgent.dynamicModel</code> Enable model switch by request. Not changable. Populated by CDK <code>runtime.queueAgent.s3Bucket</code> S3 bucket for generated image. Not changable. Populated by CDK <code>runtime.queueAgent.snsTopicArn</code> SNS topic for image generate complete notification. Not changable. Populated by CDK <code>runtime.queueAgent.sqsQueueUrl</code> SQS queue URL of job queue. Not changable. Populated by CDK <code>runtime.queueAgent.resources</code> Resource request and limit for queue agent. <code>runtime.queueAgent.XRay.enabled</code> Enable X-ray tracing agent for queue agent. <code>true</code> Persistence <code>runtime.persistence.enabled</code> Enable presistence of model stroage. <code>true</code> <code>runtime.persistence.labels</code> Labels applied to presistence volume. Should be in key-values format. <code>{}</code> <code>runtime.persistence.annotations</code> Annotations applied to presistence volume. Should be in key-values format. <code>{}</code> <code>runtime.persistence.storageClass</code> Storage class for model storage <code>s3-model-storage-sc</code> <code>runtime.persistence.size</code> Size of persistence volume. <code>2Ti</code> <code>runtime.persistence.accessModes</code> Access mode of persistence volume. <code>ReadWriteMany</code>"},{"location":"implementation-guide/deployment/configuration/#deployment-examples","title":"Deployment Examples","text":"<p>We provided example config file for your reference. These config files are located in <code>/examples</code>.</p>"},{"location":"implementation-guide/deployment/configuration/#multiple-runtimes","title":"Multiple Runtimes","text":"<p>You can add multiple runtimes with different models by adding entries in <code>modelsRuntime</code> array. Each runtime should have different <code>modelFilename</code>. We recommand deploying runtimes in their own namespace.</p> <pre><code>modelsRuntime:\n- name: \"sdruntime1\" # First runtime\n  namespace: \"sdruntime1\"\n  modelFilename: \"v1-5-pruned-emaonly.safetensors\"\n- name: \"sdruntime2\" # Second runtime\n  namespace: \"sdruntime2\"\n  modelFilename: \"v2-1_768-ema-pruned.safetensors\"\n</code></pre> <p>See <code>multiple-runtimes.yaml</code> for more reference.</p>"},{"location":"implementation-guide/deployment/configuration/#dynamic-model-runtime","title":"Dynamic Model Runtime","text":"<p>By default, models are pre-loaded to runtime. Each runtime only accept request with its model filename. You can create dynamic model runtime as a catch-all option. By enabling dynamic model runtime, a new runtime with default model <code>v1-5-pruned-emaonly.safetensors</code> is created. This runtime will accept all requests without a matching runtime. Then, the runtime will load model by request. Models should be stored in S3 bucket before sending a request with this model.</p> <pre><code>dynamicModelRuntime:\n  enabled: true # Enable dynamic model runtime by change the value to \"true\"\n  namespace: \"default\"\n</code></pre> <p>See <code>dynamic-runtime.yaml</code> for more reference.</p>"},{"location":"implementation-guide/deployment/considerations/","title":"Deployment Consideration","text":"<p>Please check the following considerations before deployment:</p>"},{"location":"implementation-guide/deployment/considerations/#deployable-regions","title":"Deployable Regions","text":"<p>The services or Amazon EC2 instance types used in this solution may not be available in all AWS regions. Launch this solution in an AWS region that provides the required services.</p> <p>Verified Deployable Regions</p> Region Name Verified US East (N. Virginia) US West (Oregon) <p>If deploying in an unverified region, you may need to:</p> <ul> <li>Manually specify the instance type used by Karpenter as <code>g4dn</code> or other GPU instance types when deploying in regions that do not support <code>g5</code> instances.</li> </ul> <p>Deploying in AWS China Regions</p> <p>Network Restrictions in China Regions</p> <p>Recently, we found issues when deploying this solution in China regions. The EBS failed to deploy, with error messages like <code>Waiter has timed out</code> or <code>Unexpected EOF</code>. See this issue for details.</p> <p>The root cause is that some Helm Charts are hosted on Github. When deploying in China regions, the Lambda function responsible for deploying custom resources cannot retrieve the Helm Charts, causing failures. We are actively working on this issue and will copy the required Helm Charts and container images to China regions.</p> <p>If you encounter this issue during deployment, please switch to a non-China region for testing, or set up your own Helm repo as a temporary solution.</p> <p>This solution can be deployed in AWS China regions.</p> Region Name Verified China (Ningxia), operated by NWCD <p>When deploying in China regions, due to environment limitations, you may need to:</p> <ul> <li>China regions do not support the default <code>g5</code> instance type. You need to manually specify the instance type used by Karpenter as <code>g4dn</code> or other GPU instance types.</li> </ul>"},{"location":"implementation-guide/deployment/considerations/#iam-permissions","title":"IAM Permissions","text":"<p>Deploying this solution requires administrator or equivalent permissions. Due to the number of components, we do not provide a minimal permissions list.</p>"},{"location":"implementation-guide/deployment/considerations/#service-quotas","title":"Service Quotas","text":"<p>Each AWS account has quotas on the number of resources that can be created in each AWS region. You can view service quotas in the AWS console using the Service Quotas tool. If a service quota can be increased, you can open a case through this tool to request an increase.</p> <p>The main service quotas related to this solution are:</p> AWS Service Quota Entry Estimated Usage Adjustable Amazon EC2 Running On-Demand G and VT instances Based on max concurrent GPU instances Amazon EC2 All G and VT Spot Instance Requests Based on max concurrent GPU instances Amazon SNS Messages Published per Second Based on max concurrent requests <p>Additionally, consider the following service quotas during deployment:</p> AWS Service Quota Entry Estimated Usage Adjustable Amazon VPC VPCs per Region 1 Amazon VPC NAT gateways per Availability Zone 1 Amazon EC2 EC2-VPC Elastic IPs 1 Amazon S3 General purpose buckets 1 per queue"},{"location":"implementation-guide/deployment/considerations/#choose-stable-diffusion-runtime","title":"Choose Stable Diffusion Runtime","text":"<p>You need a runtime to deploy the Stable Diffusion model and provide API access.</p> <p>Currently, there are multiple community Stable Diffusion runtimes available:</p> Runtime Name Link Verified Stable Diffusion Web UI GitHub ComfyUI GitHub InvokeAI GitHub <p>You can also choose other runtimes or build your own. You need to package the runtime as a container image to run on EKS.</p> <p>You need to fully understand and comply with the license terms of the Stable Diffusion runtime you use.</p> <p>Example Runtime</p> <p>You can use the community-provided example Dockerfile to build runtime container images for Stable Diffusion Web UI and ComfyUI. Note that these images are for technical evaluation and testing purposes only, and should not be deployed to production environments.</p> <p>Model Storage</p> <p>By default, this solution will load models to the <code>/opt/ml/code/models</code> directory. Ensure your runtime is configured to read models from this directory.</p> <p>You need to disable mmap to achieve the highest performance.</p> <ul> <li>For SD Web UI, set <code>disable_mmap_load_safetensors: true</code> in <code>config.json</code></li> <li>For ComfyUI, manually modify the source code as guided in this community issue.</li> </ul> <p>Notes on SD Web UI Runtime</p> <p>For the SD Web UI runtime, there are static runtimes (pre-load models) and dynamic runtimes (load models on-demand) depending on the model being run.</p> <ul> <li>Static runtimes use models specified in <code>modelFilename</code>. The model is loaded into GPU memory at startup.</li> <li>Dynamic runtimes need to set <code>dynamicModel: true</code>. No model needs to be specified. The runtime will load the model from Amazon S3 and perform inference based on the model used in the request.</li> </ul>"},{"location":"implementation-guide/deployment/considerations/#other-important-notes-and-limitations","title":"Other Important Notes and Limitations","text":"<ul> <li> <p>In the current version, this solution will automatically create a new VPC when deployed. The VPC includes:</p> <ul> <li>CIDR <code>10.0.0.0/16</code></li> <li>3 public subnets in different availability zones, with size <code>/19</code></li> <li>3 private subnets in different availability zones, with size <code>/19</code></li> <li>3 NAT gateways (placed in public subnets)</li> <li>1 Internet gateway</li> <li>Corresponding route tables and security groups</li> </ul> <p>Currently, the parameters of this VPC cannot be customized.</p> </li> <li> <p>In the current version, this solution can only be deployed on a new EKS cluster with a fixed version of <code>1.28</code>. We will update the cluster version as new Amazon EKS versions are released.</p> </li> </ul>"},{"location":"implementation-guide/deployment/deploy/","title":"Quick start","text":""},{"location":"implementation-guide/deployment/deploy/#provision-infrastructure-and-runtime","title":"Provision infrastructure and runtime","text":"<p>Required infrastructure and application is deployed via AWS CDK. We provide default configuration and image for quick start.</p> <p>Run the following command to clone the code:</p> <pre><code>git clone --recursive &lt;repo path&gt;\ncd stable-diffusion-on-eks\n</code></pre> <p>Before deploy, you need to edit <code>config.yaml</code> and set parameters of runtimes.</p>"},{"location":"implementation-guide/deployment/deploy/#define-model-bucket","title":"Define Model Bucket","text":"<p>Set <code>modelBucketArn</code> to the S3 bucket created on previous section.</p> <pre><code>modelBucketArn: arn:aws:s3:::&lt;bucket name&gt;\n</code></pre> <p>If you are deploying in AWS China region: <pre><code>modelBucketArn: arn:aws-cn:s3:::&lt;bucket name&gt;\n</code></pre></p>"},{"location":"implementation-guide/deployment/deploy/#define-runtime","title":"Define Runtime","text":"<p>You need to specify each runtime in <code>modelsRuntime</code> section. For each runtime, specify the following value:</p> <pre><code>modelsRuntime:\n- name: \"sdruntime\" # Name of runtime, should be unique\n  namespace: \"default\" # Namespace of runtime, suggest deploy different runtimes on seperate namespaces\n  modelFilename: \"v1-5-pruned-emaonly.safetensors\" # Model for this runtime, request will be routed by model filename.\n  type: \"SDWebUI\" # Specify type of runtime. Different type of runtime represents different API Spec.\n  extraValues:\n    runtime:\n      inferenceApi:\n        image:\n          repository: sdoneks/inference-api # Image repository of your runtime\n          tag: latest # Image tag of your runtime\n    queueAgent:\n      image:\n        repository: sdoneks/queue-agent # Image repository for queue agent\n        tag: latest # Image tag of queue agent\n</code></pre>"},{"location":"implementation-guide/deployment/deploy/#deploy","title":"Deploy","text":"<p>Run the following command to deploy the stack:</p> <pre><code>npm install\ncdk synth\ncdk deploy --all\n</code></pre> <p>Deployment requires 20-30 minutes.</p>"},{"location":"implementation-guide/deployment/deploy/#usage","title":"Usage","text":"<p>After deployment completes, you can get endpoint and key of API on CDK output:</p> <pre><code>Outputs:\nSdOnEksDataPlaneStack.APIKey = 1234567890abcdefghij\nSdOnEksDataPlaneStack.FrontApiEndpoint = https://abcdefghij.execute-api.ap-southeast-1.amazonaws.com/prod/\n...\n</code></pre> <p>You can try it out by making API call with prompt. Your request should follow API Spec of corresponding runtime. For Stable Diffusion Web UI, save the following content as a JSON file:</p> <pre><code>{\n    \"alwayson_scripts\": {\n        \"task\": \"text-to-image\",\n        \"sd_model_checkpoint\": \"v1-5-pruned-emaonly.safetensors\",\n        \"id_task\": \"123\",\n        \"uid\": \"123\",\n        \"save_dir\": \"outputs\"\n    },\n    \"prompt\": \"A dog\",\n    \"steps\": 16,\n    \"width\": 512,\n    \"height\": 512\n}\n</code></pre> <p>Now you can use <code>curl</code> to test the solutions. Copy the following cURL command and paste it into the terminal window, replacing <code>1234567890abcdefghij</code> with content of <code>SdOnEksDataPlaneStack.APIKey</code>, <code>https://abcdefghij.execute-api.ap-southeast-1.amazonaws.com/prod/</code> with the content of <code>SdOnEksDataPlaneStack.FrontApiEndpoint</code>, and <code>test.json</code> of filename you just created.</p> <pre><code>curl -X POST https://abcdefghij.execute-api.ap-southeast-1.amazonaws.com/prod/ \\\n    -H 'Content-Type: application/json' \\\n    -H 'x-api-key: 1234567890abcdefghij' \\\n    -d @test.json\n</code></pre> <p>You should get a successful response with a payload similar to the following:</p> <pre><code>{\"id_task\": \"123\", \"task\": \"text-to-image\", \"sd_model_checkpoint\": \"v1-5-pruned-emaonly.safetensors\", \"output_location\": \"s3://sdoneksdataplanestack-outputs3bucket/123\"}\n</code></pre> <p>You may need to wait for several minutes for instance launching and container starting without EBS snapshot. Once container launched and task is proceed, you can find generated image on <code>output_location</code>.</p>"},{"location":"implementation-guide/deployment/ebs-snapshot/","title":"Building EBS Snapshot","text":"<p>You can optimize launch speed by pre-caching your image as an EBS snapshot. When a new instance is launched, the data volume of the instance is pre-populated with image. When using image caching, you don't need to pull image from registry. You need to use <code>BottleRocket</code> as OS of worker node to use image caching.</p> <p>EBS snapshot should be built before deploy infrastructure. Image should be pushed to a registry (Amazon ECR) before being cached. We provided a script for building EBS snapshot.</p> <p>Run the following command to build if you have built your own image. Replace <code>us-east-1</code> to your region and <code>123456789012</code> to your AWS account 12-digit ID:</p> <pre><code>git submodule update --init --recursive\ncd utils/bottlerocket-images-cache\n./snapshot.sh 123456789012.dkr.ecr.us-east-1.amazonaws.com/sd-on-eks/inference-api:latest,123456789012.dkr.ecr.us-east-1.amazonaws.com/sd-on-eks/queue-agent:latest\n</code></pre> <p>Run the following command to build if you want to use pre-built image from Dockerhub:</p> <pre><code>git submodule update --init --recursive\ncd utils/bottlerocket-images-cache\n./snapshot.sh sdoneks/inference-api:latest,sdoneks/queue-agent:latest\n</code></pre> <p>This script will launch an instance, pull image from registry, and capture a snapshot with pulled image.</p> <p>After snapshot is built, put snapshot ID into <code>config.yaml</code>:</p> <pre><code>modelsRuntime:\n- name: \"sdruntime\"\n  namespace: \"default\"\n  modelFilename: \"v1-5-pruned-emaonly.safetensors\"\n  extraValues:\n    karpenter:\n      nodeTemplate:\n        amiFamily: Bottlerocket\n        dataVolume:\n          volumeSize: 80Gi\n          volumeType: gp3\n          deleteOnTermination: true\n          iops: 4000\n          throughput: 1000\n          snapshotID: snap-0123456789 # Change to actual snapshot ID\n</code></pre> <p>See <code>example/ebs-snapshot.yaml</code> for more reference.</p>"},{"location":"implementation-guide/deployment/image-building/","title":"Build from source","text":""},{"location":"implementation-guide/deployment/image-building/#build-image","title":"Build Image","text":"<p>You can build queue agent container image on your environment from source. <code>queue-agent</code> is for fetching message from queue and convert message to API request to Stable Diffusion Runtime.</p> <p>To build <code>queue-agent</code> image, run the following command:</p> <pre><code>docker build -t queue-agent:latest src/backend/queue_agent/\n</code></pre>"},{"location":"implementation-guide/deployment/image-building/#push-image-to-amazon-ecr","title":"Push image to Amazon ECR","text":"<p>Before pushing image, create reposirory in Amazon ECR by running the following command:</p> <pre><code>aws ecr create-repository --repository-name sd-on-eks/queue-agent\n</code></pre> <p>You can push image to Amazon ECR by running the following command. Replace <code>us-east-1</code> to your region and <code>123456789012</code> to your AWS account 12-digit ID:</p> <pre><code>aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 123456789012.dkr.ecr.us-east-1.amazonaws.com\n\ndocker tag queue-agent:latest 123456789012.dkr.ecr.us-east-1.amazonaws.com/sd-on-eks/queue-agent:latest\ndocker push 123456789012.dkr.ecr.us-east-1.amazonaws.com/sd-on-eks/queue-agent:latest\n</code></pre>"},{"location":"implementation-guide/deployment/image-building/#build-and-push-helm-chart","title":"Build and push helm chart","text":"<p>Helm chart is packaged and stored in OCI-based registry. You can store helm chart in Amazon ECR.</p> <p>Before pushing charts, create reposirory in Amazon ECR by running the following command:</p> <pre><code>aws ecr create-repository --repository-name sd-on-eks/charts/sd-on-eks\n</code></pre> <p>Package and push helm chart to Amazon ECR by running the following command. Replace <code>us-east-1</code> to your region and <code>123456789012</code> to your AWS account 12-digit ID:</p> <pre><code>helm package src/charts/sd_on_eks\nhelm push sd-on-eks-&lt;version&gt;.tgz oci://123456789012.dkr.ecr.us-east-1.amazonaws.com/sd-on-eks/charts/\n</code></pre> <p>Now your chart is stored in Amazon ECR with <code>oci://123456789012.dkr.ecr.us-east-1.amazonaws.com/sd-on-eks/charts/sd-on-eks:&lt;version&gt;</code>.</p>"},{"location":"implementation-guide/deployment/models/","title":"Create S3 bucket and store model","text":"<p>Models should be stored in S3 bucket. Stable diffusion runtime will fetch model from S3 bucket at launch.</p> <p>Create S3 bucket by running the following command. Replace <code>&lt;bucket name&gt;</code> to your desired bucket name.</p> <pre><code>aws s3api create-bucket --bucket &lt;bucket name&gt; --region us-east-1\n</code></pre> <p>You can upload model to newly created S3 bucket by running the following command:</p> <pre><code>aws s3 cp &lt;model name&gt; s3://&lt;bucket name&gt;/stable-diffusion/\n</code></pre>"},{"location":"implementation-guide/developer/source/","title":"Source code","text":"<p>Visit our GitHub repository to download the source code for this solution. The solution template is generated using the AWS Cloud Development Kit (CDK). Refer to the README.md file for more information.</p>"},{"location":"implementation-guide/observability/logging/","title":"View Logs","text":"<p>You can view the logs for this solution from CloudWatch Logs.</p> AWS Management Console <ul> <li>Open the Amazon CloudWatch console.</li> <li>In the left navigation pane, choose Logs - Log groups.</li> <li>Select the corresponding log group. The log group format is <code>/aws/eks/fluentbit-cloudwatch/workload/default</code>, replace <code>default</code> with the Kubernetes namespace where the runtime is located.</li> <li>You can select the corresponding Log Stream to view logs for different components or choose Search all log streams to search logs.</li> </ul>"},{"location":"implementation-guide/observability/monitoring/","title":"View Monitoring","text":"<p>You can view the monitoring metrics for this solution in CloudWatch.</p> <p>The monitoring metrics are provided by Container Insight. Refer to Amazon EKS and Kubernetes Container Insights metrics for metric details.</p> AWS Management Console <ul> <li>Open the Amazon CloudWatch console.</li> <li>In the left navigation pane, choose Metrics - All Metrics.</li> <li>Select ContainerInsights.</li> <li>Choose ClusterName, Namespace, PodName.</li> <li>You can view metrics for different replicas of the runtime based on PodName.</li> </ul>"},{"location":"implementation-guide/operation/kubernetes-cluster/","title":"Kubernetes Cluster Management","text":"<p>You can use the <code>kubectl</code> command to connect to the cluster created by the solution, retrieve the current system status, and make customizations.</p>"},{"location":"implementation-guide/operation/kubernetes-cluster/#install-kubectl","title":"Install kubectl","text":"<p>Refer to the Installing or updating kubectl documentation to install the <code>kubectl</code> command-line tool. Install a version of kubectl that is compatible with Kubernetes 1.28.</p>"},{"location":"implementation-guide/operation/kubernetes-cluster/#log-in-to-the-kubernetes-cluster","title":"Log in to the Kubernetes Cluster","text":"<p>You can find the command to connect to the EKS cluster from the CloudFormation output:</p> AWS Management ConsoleAWS CLI <ul> <li>Go to the AWS CloudFormation console</li> <li>Choose Stacks</li> <li>In the list, select SdOnEKSStack (or your custom name)</li> <li>Choose Output</li> <li>Record the value of the ConfigCommand item</li> <li>Run that command in your terminal.</li> </ul> <p>Run the following command to retrieve the command:</p> <pre><code>aws cloudformation describe-stacks --stack-name SdOnEKSStack --output text --query 'Stacks[0].Outputs[?OutputKey==`ConfigCommand`].OutputValue'\n</code></pre> <p>Run that command in your terminal.</p>"},{"location":"implementation-guide/solution-overview/cost/","title":"Cost Estimation","text":"<p>Important</p> <p>The cost estimation described in this section is only an example and may vary depending on your environment.</p> <p>You will incur costs for using various Amazon Web Services when running the solution. The main factors affecting the cost of the solution include:</p> <ul> <li>Instance types and purchasing options chosen</li> <li>Volume of generated images</li> <li>Elastic scaling configurations</li> </ul>"},{"location":"implementation-guide/usage/","title":"Use API","text":"<p>After deploying the solution, you can send requests to the Stable Diffusion runtime through the API endpoint of Amazon API Gateway.</p> <p>When sending requests, please follow these rules:</p>"},{"location":"implementation-guide/usage/#api-request-example","title":"API Request Example","text":"<p>You can use the test script to verify if the solution is deployed successfully. Run the following command to test:</p> <pre><code>cd test\nSTACK_NAME=sdoneksStack RUNTIME_TYPE=sdwebui ./run.sh\n</code></pre> <p>If you modified the solution stack name or runtime type, replace <code>sdoneksStack</code> and <code>sdwebui</code> accordingly.</p> <p>The script will automatically find the API Gateway endpoint, get the API Key, and send a test request.</p> <ul> <li>For SD Web UI runtime, it will send a text-to-image and image-to-image request.</li> <li>For ComfyUI runtime, it will send a Pipeline request.</li> </ul> <p>After a few seconds to a few minutes (depending on whether image caching is enabled and the minimum number of instance replicas), you can find the generated images at the <code>output_location</code>.</p>"},{"location":"implementation-guide/usage/#request-endpoint-and-format","title":"Request Endpoint and Format","text":"<p>You can get the solution's API endpoint from the CloudFormation outputs:</p> AWS Management ConsoleAWS CLI <ul> <li>Go to the AWS CloudFormation Console</li> <li>Select Stacks</li> <li>In the list, select SdOnEKSStack (or your custom name)</li> <li>Select Output</li> <li>Note the value of FrontApiEndpoint (in the format <code>https://abcdefghij.execute-api.ap-southeast-1.amazonaws.com/prod/</code>)</li> </ul> <p>Run the following command to get the API endpoint:</p> <pre><code>aws cloudformation describe-stacks --stack-name SdOnEKSStack --output text --query 'Stacks[0].Outputs[?OutputKey==`FrontApiEndpoint`].OutputValue'\n</code></pre> <p>You need to append the API version to the endpoint. Currently, we support <code>v1alpha1</code> and <code>v1alpha2</code> versions. When using the <code>v1alpha2</code> version API, requests should be sent to:</p> <pre><code>https://abcdefghij.execute-api.ap-southeast-1.amazonaws.com/prod/v1alpha2\n</code></pre> <p>The endpoint only accepts JSON formatted POST requests with the <code>Content-Type: application/json</code> request header.</p>"},{"location":"implementation-guide/usage/#request-types","title":"Request Types","text":"<p>Depending on the runtime type, each runtime only accepts specific types of requests:</p> <ul> <li>For SD Web UI runtime, it only accepts text-to-image and image-to-image requests.</li> <li>For ComfyUI runtime, it only accepts Pipeline requests.</li> </ul> <p>Please refer to the detailed documentation for each request type for the specific request format.</p>"},{"location":"implementation-guide/usage/#api-key","title":"API Key","text":"<p>For security reasons, all requests need to include an API Key. Follow these steps to get the API Key:</p> AWS Management ConsoleAWS CLI <ul> <li>Go to the Amazon API Gateway Console</li> <li>Select API Keys</li> <li>In the list, select the API Key with a name similar to <code>SdOnEK-defau-abcdefghij</code> (or your custom name)</li> <li>Note the value of the API key</li> </ul> <p>Run the following command to get the API Key:</p> <pre><code>echo $(aws cloudformation describe-stacks --stack-name SdOnEKSStack --output text --query 'Stacks[0].Outputs[?OutputKey==`GetAPIKeyCommand`].OutputValue')\n</code></pre> <p>When sending requests, you need to include the <code>x-api-key</code> request header with the value being the API Key obtained above.</p> <p>Unverified Requests</p> <p>Requests without an API Key will directly return a <code>401</code> error.</p>"},{"location":"implementation-guide/usage/#throttling-rules","title":"Throttling Rules","text":"<p>To protect the backend API, API Gateway will throttle excessive requests sent using the same API Key.</p> <p>The default setting is:</p> <ul> <li>30 requests per second</li> <li>Burst of 50 requests</li> </ul> <p>For detailed information about throttling principles, please refer to Throttle API requests for better throughput</p> <p>If you need to modify this setting, please change the relevant content in the <code>APIGW</code> section of <code>config.yaml</code>. You can also modify the corresponding Usage Plan in API Gateway.</p>"},{"location":"implementation-guide/usage/#next-steps","title":"Next Steps","text":"<p>Based on the different use cases in the right-side menu, send requests to Stable Diffusion.</p>"},{"location":"implementation-guide/usage/callback/","title":"Callbacks and Notifications","text":"<p>The Stable Diffusion on Amazon EKS solution uses an asynchronous inference mode. When an image is generated or an error occurs, users will be notified through Amazon SNS. User applications can subscribe to the SNS topic to receive notifications when image generation is complete.</p>"},{"location":"implementation-guide/usage/callback/#adding-subscriptions","title":"Adding Subscriptions","text":"<p>Please refer to the Amazon SNS documentation to understand the types of message destinations supported by SNS.</p> <p>You can find the ARN of the generated SNS topic in the outputs of CloudFormation:</p> AWS Management ConsoleAWS CLI <ul> <li>Go to the AWS CloudFormation Console</li> <li>Select Stacks</li> <li>In the list, select SdOnEKSStack (or your custom name)</li> <li>Select Output</li> <li>Record the value of the sdNotificationOutputArn item (in the format <code>arn:aws:sns:us-east-1:123456789012:SdOnEKSStack-sdNotificationOutputCfn-abcdefgh</code>)</li> </ul> <p>Run the following command to get the SNS topic ARN:</p> <pre><code>aws cloudformation describe-stacks --stack-name SdOnEKSStack --output text --query 'Stacks[0].Outputs[?OutputKey==`sdNotificationOutputArn`].OutputValue'\n</code></pre> <p>To receive messages, you need to add your message receiver (such as an Amazon SQS queue, HTTP endpoint, etc.) as a subscription to this SNS topic.</p> AWS Management ConsoleAWS CLI <ul> <li>In the left navigation pane, select Subscriptions.</li> <li>On the Subscriptions page, select Create subscription.</li> <li>In the Details section of the Create subscription page, do the following:<ul> <li>For Topic ARN, select the ARN you recorded in the previous step.</li> <li>For Protocol, select the type of your receiver.</li> <li>For Endpoint, enter the address of your receiver, such as an email address or the ARN of an Amazon SQS queue.</li> </ul> </li> <li>Select Create subscription</li> </ul> <p>Please refer to Use Amazon SNS with the AWS CLI to add a subscription to this topic.</p>"},{"location":"implementation-guide/usage/callback/#callback-message-format","title":"Callback Message Format","text":"<p>The solution will send task completion notifications to SNS in the following format, regardless of the API version used in the request:</p> <pre><code>{\n    \"id\": \"task_id\", // Task ID\n    \"result\": true, // true for successful completion, false for unsuccessful completion\n    \"image_url\": [ // S3 URLs of generated images, in the format task_id+4_random_digits+image_number. If there are multiple images, all image links will be included.\n        \"s3://outputbucket/output/test-t2i/test-t2i-abcd-1.png\"\n    ],\n    \"output_url\": \"s3://outputbucket/output/test-t2i/test-t2i-abcd.out\", // S3 URL of the task output, containing the complete runtime output\n    \"context\": { // Context content included in the request\n        \"abc\": 123\n    }\n}\n</code></pre>"},{"location":"implementation-guide/usage/controlnet/","title":"ControlNet Plugin","text":""},{"location":"implementation-guide/usage/controlnet/#request-format","title":"Request Format","text":"<pre><code>{\n    \"alwayson_scripts\": {\n        // Required, task type\n        \"task\": \"text-to-image\",\n        // Required, task ID, used for uploading result images and returning responses\n        \"id_task\": \"40521\",\n        // Required, base model name, associated with queue distribution or model switching\n        \"sd_model_checkpoint\": \"v1-5-pruned-emaonly.safetensors\",\n        // Optional, user ID\n        \"uid\": \"123\",\n        // Optional, ControlNet parameters\n        \"controlnet\": {\n            \"args\": [\n                {\n                    \"image_link\": \"https://tse3-mm.cn.bing.net/th/id/OIP-C.2Z9l9li7mrfDThPW3_LE5wHaLG?pid=ImgDet&amp;rs=1\",\n                    \"module\": \"openpose\",\n                    \"model\": \"control_v11p_sd15_openpose\",\n                    \"enabled\": true,\n                    \"weight\": 1,\n                    \"resize_mode\": \"Crop and Resize\"\n                },\n                {\n                    \"image_link\": \"https://tse3-mm.cn.bing.net/th/id/OIP-C.2Z9l9li7mrfDThPW3_LE5wHaLG?pid=ImgDet&amp;rs=1\",\n                    \"module\": \"depth_leres\",\n                    \"model\": \"control_v11f1p_sd15_depth\",\n                    \"enabled\": true,\n                    \"weight\": 0.8,\n                    \"resize_mode\": \"Crop and Resize\"\n                }\n            ]\n        }\n    },\n    // All following are official parameters, use default values or pass them directly\n    \"prompt\": \"Best Quality, 1boy, wear golden LeoArmor, solo, short brown hair, looking at viewer\",\n    \"negative_prompt\": \"nsfw\",\n    \"sampler_index\": \"DPM++ SDE Karras\",\n    \"batch_size\": 1,\n    \"steps\": 16,\n    \"cfg_scale\": 7,\n    \"n_iter\": 3,\n    \"width\": 512,\n    \"height\": 512,\n    \"seed\": -1\n}\n</code></pre>"},{"location":"implementation-guide/usage/image-to-image/","title":"Image-to-Image (SD Web UI)","text":"<p>Info</p> <p>This request type is only applicable to the SD Web UI runtime.</p> <p>The basic usage of Stable Diffusion is to input a prompt and a reference image, and it can generate an image similar to the reference image.</p>"},{"location":"implementation-guide/usage/image-to-image/#request-format","title":"Request Format","text":"v1alpha2v1alpha1 <pre><code>{\n  \"task\": {\n    \"metadata\": {\n      \"id\": \"test-i2i\", // Required, task ID\n      \"runtime\": \"sdruntime\", // Required, runtime name used for the task\n      \"tasktype\": \"image-to-image\", // Required, task type\n      \"prefix\": \"output\", // Optional, prefix (directory name) for output files in the S3 bucket\n      \"context\": \"\" // Optional, can include any information, will be included in the callback\n    },\n    \"content\": { // Same specification as the SD Web UI image-to-image interface\n      \"alwayson_scripts\": {\n        \"image_link\": \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/cat.png\" // Place the image link here, the image will be downloaded, base64 encoded, and stored in the image parameter\n      },\n      \"prompt\": \"cat wizard, gandalf, lord of the rings, detailed, fantasy, cute, adorable, Pixar, Disney, 8k\",\n      \"steps\": 16,\n      \"width\": 512,\n      \"height\": 512\n    }\n  }\n}\n</code></pre> <pre><code>{\n    \"alwayson_scripts\": {\n        \"task\": \"image-to-image\", // Required, task type\n        \"image_link\": \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/cat.png\", // Required, URL of the input image\n        \"id_task\": \"test-i2i\", // Required, task ID, will be used when uploading the result image and returning the response\n        \"sd_model_checkpoint\": \"v1-5-pruned-emaonly.safetensors\", // Required, base model name, associated with queue distribution or model switching\n    },\n    // The following are official parameters, use the default values or pass them in directly\n    \"prompt\": \"cat wizard, gandalf, lord of the rings, detailed, fantasy, cute, adorable, Pixar, Disney, 8k\",\n    \"steps\": 16,\n    \"width\": 512,\n    \"height\": 512\n}\n</code></pre>"},{"location":"implementation-guide/usage/image-to-image/#response-format","title":"Response Format","text":"v1alpha2v1alpha1 <pre><code>{\n  \"id_task\": \"test-i2i\",\n  \"runtime\": \"sdruntime\",\n  \"output_location\": \"s3://outputbucket/output/test-t2i\"\n}\n</code></pre> <pre><code>{\n  \"id_task\": \"test-i2i\",\n  \"sd_model_checkpoint\": \"v1-5-pruned-emaonly.safetensors\",\n  \"output_location\": \"s3://outputbucket/output/test-t2i\"\n}\n</code></pre>"},{"location":"implementation-guide/usage/image-to-image/#getting-the-image","title":"Getting the Image","text":"<p>After the image is generated, it will be stored in the S3 bucket path specified by <code>output_location</code>. If <code>batch_size</code> or other parameters for generating multiple images are set, each image will be automatically numbered and stored.</p> <p>The default storage format is lossless PNG, but if special formats (such as GIF) are involved, the system will automatically recognize and add the extension.</p>"},{"location":"implementation-guide/usage/lora/","title":"LoRA Fine-Tuning","text":"<p>LoRA can be directly incorporated into the prompt using <code>&lt;lora:[name]:[version]&gt;</code>.</p>"},{"location":"implementation-guide/usage/lora/#request-format","title":"Request Format","text":"<pre><code>{\n    \"alwayson_scripts\": {\n        // Required, task type\n        \"task\": \"text-to-image\",\n        // Required, task ID, used for uploading result images and returning responses\n        \"id_task\": \"40521\",\n        // Required, base model name, associated with queue distribution or model switching\n        \"sd_model_checkpoint\": \"v1-5-pruned-emaonly.safetensors\",\n        // Optional, user ID\n        \"uid\": \"123\",\n    },\n    // All following are official parameters, use default values or pass them directly\n    \"prompt\": \"&lt;lora:LeoArmor:0.9&gt;, Best Quality, 1boy, wear golden LeoArmor, solo, short brown hair, looking at viewer\",\n    \"negative_prompt\": \"nsfw\",\n    \"sampler_index\": \"DPM++ SDE Karras\",\n    \"batch_size\": 1,\n    \"steps\": 16,\n    \"cfg_scale\": 7,\n    \"n_iter\": 3,\n    \"width\": 512,\n    \"height\": 512,\n    \"seed\": -1\n}\n</code></pre>"},{"location":"implementation-guide/usage/pipeline/","title":"Pipeline (ComfyUI)","text":"<p>Info</p> <p>This request type is only for ComfyUI runtime.</p> <p>This request type only provides the <code>v1alpha2</code> API.</p> <p>ComfyUI provides workflow orchestration. You can design workflows using various nodes on the interface. You can export the workflow to a <code>json</code> file.</p>"},{"location":"implementation-guide/usage/pipeline/#export-workflow","title":"Export Workflow","text":"<p>After designing the workflow on the interface, follow these steps to export: * Select the gear icon on the top right of the menu panel * Enable <code>Enable Dev mode Options</code> * Select <code>Save(API Format)</code> to save the workflow as a file</p>"},{"location":"implementation-guide/usage/pipeline/#request-format","title":"Request Format","text":"v1alpha2 <pre><code>{\n  \"task\": {\n    \"metadata\": {\n      \"id\": \"test-pipeline\", // Required, task ID\n      \"runtime\": \"sdruntime\", // Required, runtime name used\n      \"tasktype\": \"pipeline\", // Required, task type\n      \"prefix\": \"output\", // Optional, output file prefix (directory) in S3 bucket\n      \"context\": \"\" // Optional, can contain any info, included in callback\n    },\n    \"content\": {\n      ... // Put exported workflow content here\n    }\n  }\n}\n</code></pre>"},{"location":"implementation-guide/usage/pipeline/#response-format","title":"Response Format","text":"v1alpha2 <pre><code>{\n  \"id_task\": \"test-pipeline\",\n  \"runtime\": \"sdruntime\",\n  \"output_location\": \"s3://outputbucket/output/test-pipeline\"\n}\n</code></pre>"},{"location":"implementation-guide/usage/pipeline/#get-images","title":"Get Images","text":"<p>After image generation completes, images are stored in the S3 bucket path specified by <code>output_location</code>. If <code>batch_size</code> or other multi-image parameters are set, each image gets an auto-numbered filename.</p> <p>Default storage format is lossless PNG, but system auto-detects and adds extensions for special formats like GIF.</p>"},{"location":"implementation-guide/usage/text-to-image/","title":"Text-to-Image (SD Web UI)","text":"<p>Info</p> <p>This request type is only applicable to the SD Web UI runtime.</p> <p>The most basic usage of Stable Diffusion is to input a prompt and generate a corresponding image.</p>"},{"location":"implementation-guide/usage/text-to-image/#request-format","title":"Request Format","text":"v1alpha2v1alpha1 <pre><code>{\n  \"task\": {\n    \"metadata\": {\n      \"id\": \"test-t2i\", // Required, task ID\n      \"runtime\": \"sdruntime\", // Required, runtime name used for the task\n      \"tasktype\": \"text-to-image\", // Required, task type\n      \"prefix\": \"output\", // Optional, prefix (directory name) for output files in the S3 bucket\n      \"context\": \"\" // Optional, can include any information, will be included in the callback\n    },\n    \"content\": { // Same specification as the SD Web UI text-to-image interface\n      \"alwayson_scripts\": {},\n      \"prompt\": \"A dog\",\n      \"steps\": 16,\n      \"width\": 512,\n      \"height\": 512\n    }\n  }\n}\n</code></pre> <pre><code>{\n    \"alwayson_scripts\": {\n        \"task\": \"text-to-image\", // Required, task type\n        \"sd_model_checkpoint\": \"v1-5-pruned-emaonly.safetensors\", // Required, base model name, associated with queue distribution or model switching\n        \"id_task\": \"test-t2i\", // Required, task ID, will be used when uploading result images and returning responses\n        \"save_dir\": \"outputs\" // Required, prefix (directory name) for output files in the S3 bucket\n    },\n    // The following are official parameters, use default values or pass them directly\n    \"prompt\": \"A dog\",\n    \"steps\": 16,\n    \"width\": 512,\n    \"height\": 512\n}\n</code></pre>"},{"location":"implementation-guide/usage/text-to-image/#response-format","title":"Response Format","text":"v1alpha2v1alpha1 <pre><code>{\n  \"id_task\": \"test-t2i\",\n  \"runtime\": \"sdruntime\",\n  \"output_location\": \"s3://outputbucket/output/test-t2i\"\n}\n</code></pre> <pre><code>{\n  \"id_task\": \"test-t2i\",\n  \"sd_model_checkpoint\": \"v1-5-pruned-emaonly.safetensors\",\n  \"output_location\": \"s3://outputbucket/output/test-t2i\"\n}\n</code></pre>"},{"location":"implementation-guide/usage/text-to-image/#image-retrieval","title":"Image Retrieval","text":"<p>After the image generation is complete, it will be stored in the S3 bucket path specified by <code>output_location</code>. If <code>batch_size</code> or other parameters for generating multiple images are set, each image will be automatically numbered and stored.</p> <p>The default storage format is lossless PNG, but if special formats (such as GIF) are involved, the system will automatically recognize and add the extension.</p>"}]}