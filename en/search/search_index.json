{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Stable Diffusion on EKS","text":"<p>Implementing a fast scaling and low cost Stable Diffusion inference solution with serverless and containers on AWS</p> <p>Stable Diffusion is a popular open source project for generating images using Gen AI. Building a scalable and cost efficient inference solution is a common challenge AWS customers facing. This project shows how to use serverless and container services to build an end-to-end low cost and fast scaling asyncronous image generation architecture. This repo contains the sample code and CDK deployment scripts, helping you to deploy this solution in a few steps.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Asyncronous API and Serverless Event-Driven Architecture</li> <li>Image Generation with Stable Diffusion Web UI on Amazon EKS</li> <li>Automatic queue length based scaling with KEDA</li> <li>Automatic provisioning ec2 instances with Karpenter</li> <li>Scaling up new inference nodes within 2 minutes</li> <li>Saving up to 70% with GPU spot instances</li> </ul> <p>Disclaimer</p> <p>This solution is provided solely as a reference architecture and example code, offered to you under the MIT-0 License.</p> <p>This solution is intended for demonstration, proof of concept, or learning purposes only. You should not deploy this solution directly in your production account or use it for production or other critical data.</p> <p>Deploying this solution may result in AWS charges due to the creation or use of chargeable AWS resources (such as running Amazon EC2 instances or using Amazon S3 storage).</p>"},{"location":"implementation-guide/faq/","title":"Frequently Asked Questions","text":""},{"location":"implementation-guide/faq/#general-questions","title":"General Questions","text":"<ul> <li> <p>What is the Stable Diffusion on Amazon EKS solution?</p> <p>The Stable Diffusion on Amazon EKS solution is a reference architecture for deploying Stable Diffusion on Amazon Web Services. This reference architecture is designed based on an event-driven architecture and leverages modern application services such as serverless and containers. With this solution, users can quickly deploy Stable Diffusion for inferencing and generating images on Amazon Web Services, meeting requirements for rapid on-demand scaling, high availability, and cost-effectiveness.</p> </li> <li> <p>What makes this solution unique?</p> <p>The Stable Diffusion on Amazon EKS solution is designed based on an event-driven architecture, utilizing KEDA for automatic scaling based on queue length. It can effectively handle high-concurrency inference requests and, with the help of Karpenter and Bottlerocket, rapidly scale new inference nodes, greatly reducing image generation wait times. Additionally, the solution supports the use of GPU Spot instances, enabling customers to utilize the required computing resources at a lower cost. The solution also supports multiple community Stable Diffusion runtimes and provides unified management through the Kubernetes API for underlying Amazon EKS, offering openness and flexibility. Customers can easily customize this reference architecture to meet their specific business requirements.</p> </li> <li> <p>When is it more suitable for me to use Stable Diffusion on Amazon EKS?</p> <p>Compared to other solutions using Stable Diffusion on Amazon Web Services, this solution is more suitable for business workloads with high concurrent requests or fluctuating demands, where low-latency image generation performance is crucial. Alternatively, for customers already using the Kubernetes technology stack as a resource scheduling and management platform or for customers with more customization requirements, this solution can provide additional benefits.</p> </li> <li> <p>What AWS services does this solution use?</p> <p>Please refer to the AWS Services page.</p> </li> <li> <p>How does AWS support this solution?</p> <p>This solution is provided by the AWS Solutions Architecture team under the MIT-0 license. The solution currently only receives community support. If you encounter bugs in the solution code or have feature suggestions, please contact us through GitHub.</p> <p>If there are issues with AWS products or services mentioned in the solution, you can contact AWS support based on your support plan.</p> <p>The AWS Solutions Architecture team can provide solution discussions, workshops, and deployment support. If you need assistance, please contact your customer team or contact us through this webpage.</p> </li> <li> <p>How do I deploy this solution?</p> <p>We provide a one-click deployment template based on AWS CDK, allowing you to deploy this solution in your AWS account. You can customize the deployment through various configuration options in the configuration file. After deployment, you can further extend the solution.</p> </li> <li> <p>Which instance types can I use?</p> <p>Currently, you can use accelerated computing instances in the corresponding region. Instances such as g5, g4dn, and p3 have been tested and are supported. g3 instances are not supported due to driver issues. inf series instances are not supported at this time. CPU instance types generate images more slowly and are not recommended for use.</p> </li> </ul>"},{"location":"implementation-guide/release-notes/","title":"Release note","text":"Date Update Description October 2023 Initial release"},{"location":"implementation-guide/uninstall/","title":"Delete Solution","text":"<p>The deployed solution can be deleted using CloudFormation.</p> <p>Permanent Deletion</p> <p>All deleted resources will be permanently removed and cannot be recovered by any means.</p>"},{"location":"implementation-guide/uninstall/#deletion-scope","title":"Deletion Scope","text":"<ul> <li> <p>The following will be permanently deleted:</p> <ul> <li>Amazon EKS cluster and all worker nodes</li> <li>EFS file system</li> <li>SNS topics and all subscriptions</li> <li>SQS queues</li> <li>VPC</li> <li>IAM roles used by the solution</li> </ul> </li> <li> <p>The following will not be deleted:</p> <ul> <li>S3 bucket storing output images</li> <li>S3 bucket storing models</li> </ul> </li> </ul>"},{"location":"implementation-guide/uninstall/#pre-deletion-preparation","title":"Pre-Deletion Preparation","text":"<p>Before deleting the solution, ensure the following conditions are met:</p> <ul> <li>All SQS queues have been emptied.</li> <li>No additional policies are attached to IAM roles.</li> <li>No additional resources (such as EC2 instances, ENIs, Cloud9 environments, etc.) exist within the VPC.</li> </ul>"},{"location":"implementation-guide/uninstall/#deleting-the-solution","title":"Deleting the Solution","text":"<p>You can delete the solution using either the CDK CLI or the AWS Management Console.</p> AWS Management ConsoleAWS CDK <ul> <li>Navigate to the AWS CloudFormation console</li> <li>Select Stacks</li> <li>In the list, select SdOnEKSStack (or the name you customized)</li> <li>Select Delete, and in the pop-up dialog, choose Delete</li> </ul> <p>In the solution's source code directory, run the following command to delete the solution:</p> <pre><code>npx cdk destroy\n</code></pre> <p>Deleting the solution takes approximately 20-30 minutes.</p>"},{"location":"implementation-guide/architecture/architecture/","title":"Architecture Overview","text":""},{"location":"implementation-guide/architecture/architecture/#architecture-diagram","title":"Architecture Diagram","text":""},{"location":"implementation-guide/architecture/architecture/#components","title":"Components","text":"<p>This solution consists of three main components:</p> <ul> <li>Serverless architecture-based task scheduling and distribution</li> <li>Stable Diffusion runtime based on Amazon EKS and Amazon EC2</li> <li>Management and maintenance components</li> </ul>"},{"location":"implementation-guide/architecture/architecture/#task-scheduling-and-distribution","title":"Task Scheduling and Distribution","text":"<p>This component includes an API endpoint based on Amazon API Gateway and a task distribution portion based on Amazon SNS and Amazon SQS.</p> <ul> <li>Users send requests (models, prompts, etc.) to the API endpoint provided by Amazon API Gateway.</li> <li>The request is validated by Amazon Lambda and delivered to the Amazon SNS topic.</li> <li>Amazon SNS delivers the request to the corresponding runtime's SQS queue based on the model used in the request.</li> </ul>"},{"location":"implementation-guide/architecture/architecture/#stable-diffusion-runtime","title":"Stable Diffusion Runtime","text":"<p>This component includes the Stable Diffusion runtime based on Amazon EKS, supporting elastic scaling based on requests.</p> <p>For each runtime:</p> <ul> <li>Application backend sends the prompt to Amazon API Gateway, Amazon Lambda validates the requests, and publishes to an Amazon SNS topic</li> <li>SNS publishes the message to Amazon SQS queues via matching subscription filters</li> <li>In Amazon EKS cluster, open source Kubernetes Event Driven Auto-Scaler\u00a0(KEDA) scales up new pods based on the queue length</li> <li>Karpenter (an open source Kubernetes compute auto-scaler) launches new GPU spot instances to place pending pods. The nodes run Bottlerocket OS with pre-cached Stable Diffusion Runtime images</li> <li>SD Runtime loads model files from Amazon EFS file system</li> <li>Queue Agent calls SD Runtime to generate images and save them to Amazon S3</li> <li>Queue Agent sends output to a SNS topic and the application backend receives notification from SQS queue</li> <li>Amazon CloudWatch, Amazon Distro for OpenTelemetry, and Amazon X-Ray collect metrics, logs, and traces to monitor guidance components</li> <li>Amazon IAM for security and resource access control, Amazon CDK for automated deployment of guidance components into AWS</li> </ul> <p>Depending on the model's nature, runtimes are categorized into static runtimes (pre-loaded models) and dynamic runtimes (on-demand loaded models).</p>"},{"location":"implementation-guide/architecture/architecture/#static-runtimes","title":"Static Runtimes","text":"<p>Static runtimes use models that need to be specified in advance and loaded into memory at startup. SNS only delivers requests using the specified model to the corresponding runtime.</p>"},{"location":"implementation-guide/architecture/architecture/#dynamic-runtimes","title":"Dynamic Runtimes","text":"<p>Dynamic runtimes do not require specifying models in advance. SNS delivers all requests without static runtimes to this runtime. The runtime loads the model from Amazon EFS and performs model inference based on the model used in the request.</p> <p>Note</p> <p>In the current implementation, requests are randomly distributed to one of the replicas of dynamic runtimes. This routing strategy may lead to unnecessary model loading, resulting in longer image generation times.</p>"},{"location":"implementation-guide/architecture/architecture/#management-and-maintenance","title":"Management and Maintenance","text":"<p>This solution provides comprehensive observability and management components:</p> <ul> <li>Numeric monitoring and logs based on CloudWatch</li> <li>End-to-end tracing based on AWS X-Ray</li> <li>Infrastructure as code deployment using AWS CDK</li> </ul>"},{"location":"implementation-guide/architecture/services-in-this-solution/","title":"AWS Services in the solution","text":"<p>The following AWS services are included in this solution:</p> AWS Service Description Amazon S3 Used for storing models and generated images. Amazon EFS Used for storing models. Amazon Datasync Used to sync models from S3 buckets to EFS. Amazon ECR Used for storing container images required by the runtime. Amazon API Gateway Used to provide an API interface for external access. AWS Lambda Used for request validation and routing. Amazon SQS Used to store pending tasks for processing. Amazon SNS Used to route tasks to different SQS queues and provide notifications and callbacks after processing is complete. Amazon EKS Used for managing and running the Stable Diffusion runtime. Amazon EC2 Used for running the Stable Diffusion runtime. Amazon CloudWatch Used for monitoring the system's operation, providing numerical monitoring, logs, and tracing. AWS CDK Used for deploying and updating this solution."},{"location":"implementation-guide/deployment/","title":"Overview","text":"<p>Before deploying the solution, it is recommended to review information in this guide, such as the architecture diagram and region support. Then, follow the instructions below to configure and deploy the solution to your account.</p>"},{"location":"implementation-guide/deployment/#prerequisites","title":"Prerequisites","text":"<p>Check if all considerations are met according to the Deployment Considerations document.</p>"},{"location":"implementation-guide/deployment/#deployment-steps","title":"Deployment Steps","text":"<p>Deploy this solution on AWS using the following steps.</p> <ol> <li>Create the Amazon S3 Model Bucket and store the required models in the bucket.</li> <li>(Optional) Build Container Images.</li> <li>(Optional) Store Container Images in EBS Snapshots for Faster Startups.</li> <li>Deploy and Launch the Solution Stack.</li> </ol> <p>The total deployment time is approximately 30 minutes.</p>"},{"location":"implementation-guide/deployment/#get-the-source-code","title":"Get the Source Code","text":"<p>Run the following commands to get the source code and deployment scripts:</p> <pre><code>git clone --recursive https://github.com/aws-samples/stable-diffusion-on-eks\ncd stable-diffusion-on-eks\n</code></pre>"},{"location":"implementation-guide/deployment/configuration/","title":"Configuration","text":""},{"location":"implementation-guide/deployment/configuration/#infrastructure","title":"Infrastructure","text":"<p>We use config file to customize infrastructure and runtime. By default, the config file name is <code>config.yaml</code>. You can use alternative config file by changing environment variable <code>CDK_CONFIG_PATH</code>.</p> <p>The following table lists the configurable parameters of CDK template and the default values.</p> Parameter Description Required Default <code>stackName</code> Name of the stack. The name will be added as a prefix of all resource name. Yes <code>SdOnEKS</code> <code>modelBucketArn</code> S3 bucket for model storage. Models file should be manual populated into the bucket. This parameter applies to all runtimes. Yes <code>\"\"</code> <code>modelsRuntime</code> Define Stable diffusion runtime. At least one runtime should be defined. Yes <code>- name: \"sdruntime\"  modelFilename: \"v1-5-pruned-emaonly.ckpt\"</code> <code>modelsRuntime.name</code> Name of individual Stable diffusion runtime. Yes <code>sdruntime</code> <code>modelsRuntime.namespace</code> Namespace of individual Stable diffusion runtime. Yes <code>default</code> <code>modelsRuntime.chartRepository</code> Override default helm chart repository. Protocol (<code>oci://</code> or <code>https://</code>)should be added as a prefix of repository. (Default: <code>https://aws-samples.github.io/stable-diffusion-on-eks</code>) No N/A <code>modelsRuntime.chartVersion</code> Override version of helm chart. (Default: 0.1.0) No N/A <code>modelsRuntime.modelFilename</code> File of model using in the runtime. Filename should be in <code>.ckpt</code> or <code>.safetensors</code> format. Filename should be quoted if contains number only. Yes <code>v1-5-pruned-emaonly.safetensors</code> <code>modelsRuntime.extraValues</code> Extra parameter passed to the runtime. See values definition for detail. No N/A <code>dynamicModelRuntime.enabled</code> Generate a runtime which allows models be switched by request. See multi model support for detail. Yes <code>false</code> <code>dynamicModelRuntime.namespace</code> Namespace of dynamic model runtime. Required if <code>dynamicModelRuntime.enabled</code> is <code>true</code>. No <code>default</code> <code>dynamicModelRuntime.chartRepository</code> Override default helm chart repository. (Default: <code>https://aws-samples.github.io/stable-diffusion-on-eks</code>) No N/A <code>dynamicModelRuntime.chartVersion</code> Override version of helm chart. (Default: 0.1.0) No N/A <code>dynamicModelRuntime.extraValues</code> Extra parameter passed to the runtime. See values definition for detail. No N/A"},{"location":"implementation-guide/deployment/configuration/#application-helm-chart","title":"Application (Helm Chart)","text":"<p>Stable diffusion runtime are deployed via helm chart. You can customize individual stable diffusion runtime by passing values via <code>modelsRuntime.extraValues</code>.</p> <p>The following table lists the configurable parameters of helm chart and the default values. All values are not mandatory. Please some value will be populated by CDK, and not changeable by user.</p> Parameter Description Default Global <code>global.awsRegion</code> AWS region where the stack resides. Not changable. Populated by CDK <code>global.stackName</code> Name of CDK stack. Not changable. Populated by CDK Karpenter Provisioner <code>karpenter.provisioner.labels</code> Labels applied to all nodes. Should be in key-values format. <code>{}</code> <code>karpenter.provisioner.capacityType.onDemand</code> Allow Karpenter to launch on-demand node. <code>true</code> <code>karpenter.provisioner.capacityType.spot</code> Allow Karpenter to create spot node. When <code>provisioner.capacityType.onDemand</code> is true, Karpenter will priortize launching Spot instance. <code>true</code> <code>karpenter.provisioner.instanceType</code> An array of instance types Karpenter can launch. Should only include instance type available in current region. <code>- \"g5.xlarge\"</code> <code>karpenter.provisioner.extraRequirements</code> Additional requirement for Karpenter to choose instance type. <code>[]</code> <code>karpenter.provisioner.extraTaints</code> Provisioned nodes will have <code>nvidia.com/gpu:NoSchedule</code> and <code>runtime:NoSchedule</code> taints by default. Use this paremeter for additional taints. <code>[]</code> <code>karpenter.provisioner.resourceLimits</code> Resource limits prevent Karpenter from creating new instances once the limit is exceeded. <code>cpu</code>, <code>memory</code> and <code>nvidia.com/gpu</code> are supported. <code>nvidia.com/gpu: 100</code> <code>karpenter.provisioner.consolidation</code> Enables consolidation which attempts to removing un-needed nodes and down-sizing those that can't be removed. <code>true</code> Karpenter Node Template <code>karpenter.nodeTemplate.securityGroupSelector</code> Tagged security groups will be attached to instances. Not changable. Populated by CDK <code>karpenter.nodeTemplate.subnetSelector</code> Instances will be launched in tagged subnets. Not changable. Populated by CDK <code>karpenter.nodeTemplate.tags</code> Tags applied to all nodes. Should be in key-values format. <code>{}</code> <code>karpenter.nodeTemplate.amiFamily</code> OS option for worker nodes. Karpenter will automatically query for the appropriate EKS optimized AMI via AWS Systems Manager (SSM). <code>AL2</code> and <code>Bottlerocket</code> are supported. <code>Bottlerocket</code> <code>karpenter.nodeTemplate.osVolume</code> Control the Elastic Block Storage (EBS) volumes that Karpenter attaches to provisioned nodes. See this for schema. This volume will be attached to <code>/dev/xvda</code>. <code>karpenter.nodeTemplate.dataVolume</code> Control the Elastic Block Storage (EBS) volumes that Karpenter attaches to provisioned nodes. See this for schema. This volume will be attached to <code>/dev/xvdb</code>. Required when using <code>Bottlerocket</code>. <code>karpenter.nodeTemplate.userData</code> UserData that is applied to your worker nodes. See the examples here for format. <code>\"\"</code> sdWebuiInferenceApi <code>sdWebuiInferenceApi.labels</code> Labels applied to all resources. Should be in key-values format. <code>\"\"</code> <code>sdWebuiInferenceApi.annotations</code> Annotations applied to stable diffusion runtime. Should be in key-values format. <code>\"\"</code> <code>sdWebuiInferenceApi.serviceAccountName</code> Name of service account used by runtime. Not changable. Populated by CDK <code>sdWebuiInferenceApi.replicas</code> Replica count of runtime. <code>1</code> <code>sdWebuiInferenceApi.scaling.enabled</code> Enable auto scaling by SQS length. <code>true</code> <code>sdWebuiInferenceApi.scaling.queueLength</code> Target value for queue length. KEDA will scale pod to <code>ApproximateNumberOfMessage / queueLength</code> replicas. <code>10</code> <code>sdWebuiInferenceApi.scaling.cooldownPeriod</code> The period (in seconds) to wait after the last trigger reported active before scaling the resource back to <code>minReplicaCount</code>. <code>60</code> <code>sdWebuiInferenceApi.scaling.maxReplicaCount</code> This setting is passed to the HPA definition that KEDA will create for a given resource and holds the maximum number of replicas of the target resource. <code>20</code> <code>sdWebuiInferenceApi.scaling.minReplicaCount</code> Minimum number of replicas KEDA will scale the resource down to. <code>0</code> <code>sdWebuiInferenceApi.scaling.pollingInterval</code> Interval (in seconds) to check each trigger on. <code>1</code> <code>sdWebuiInferenceApi.scaling.scaleOnInFlight</code> When set to <code>true</code>, not visible (in-flight) messages will be counted in <code>ApproximateNumberOfMessage</code> <code>false</code> <code>sdWebuiInferenceApi.scaling.extraHPAConfig</code> KEDA would feed values from this section directly to the HPA\u2019s <code>behavior</code> field. Follow Kubernetes documentation for details. <code>{}</code> Stable Diffusion Runtime <code>sdWebuiInferenceApi.inferenceApi.image.repository</code> Image Repository of Runtime. <code>sdoneks/inference-api</code> <code>sdWebuiInferenceApi.inferenceApi.image.tag</code> Image tag of Runtime. <code>latest</code> <code>sdWebuiInferenceApi.inferenceApi.modelFilename</code> Model filename of Runtime. Not changable. Populated by CDK <code>sdWebuiInferenceApi.inferenceApi.extraEnv</code> Extra environment variable for Runtime. Should be in Kubernetes format. <code>{}</code> <code>sdWebuiInferenceApi.inferenceApi.resources</code> Resource request and limit for Runtime. Queue Agent <code>sdWebuiInferenceApi.queueAgent.image.repository</code> Image Repository of queue agent. <code>sdoneks/queue-agent</code> <code>sdWebuiInferenceApi.queueAgent.image.tag</code> Image tag of queue agent. <code>latest</code> <code>sdWebuiInferenceApi.queueAgent.extraEnv</code> Extra environment variable for queue agent. Should be in Kubernetes format. <code>{}</code> <code>sdWebuiInferenceApi.queueAgent.dynamicModel</code> Enable model switch by request. Not changable. Populated by CDK <code>sdWebuiInferenceApi.queueAgent.s3Bucket</code> S3 bucket for generated image. Not changable. Populated by CDK <code>sdWebuiInferenceApi.queueAgent.snsTopicArn</code> SNS topic for image generate complete notification. Not changable. Populated by CDK <code>sdWebuiInferenceApi.queueAgent.sqsQueueUrl</code> SQS queue URL of job queue. Not changable. Populated by CDK <code>sdWebuiInferenceApi.queueAgent.resources</code> Resource request and limit for queue agent. <code>sdWebuiInferenceApi.queueAgent.XRay.enabled</code> Enable X-ray tracing agent for queue agent. <code>true</code> Persistence <code>sdWebuiInferenceApi.persistence.enabled</code> Enable presistence of model stroage. <code>true</code> <code>sdWebuiInferenceApi.persistence.labels</code> Labels applied to presistence volume. Should be in key-values format. <code>{}</code> <code>sdWebuiInferenceApi.persistence.annotations</code> Annotations applied to presistence volume. Should be in key-values format. <code>{}</code> <code>sdWebuiInferenceApi.persistence.storageClass</code> Storage class for model storage <code>efs-model-storage-sc</code> <code>sdWebuiInferenceApi.persistence.size</code> Size of persistence volume. <code>2Ti</code> <code>sdWebuiInferenceApi.persistence.accessModes</code> Access mode of persistence volume. <code>ReadWriteMany</code>"},{"location":"implementation-guide/deployment/configuration/#deployment-examples","title":"Deployment Examples","text":"<p>We provided example config file for your reference. These config files are located in <code>/examples</code>.</p>"},{"location":"implementation-guide/deployment/configuration/#multiple-runtimes","title":"Multiple Runtimes","text":"<p>You can add multiple runtimes with different models by adding entries in <code>modelsRuntime</code> array. Each runtime should have different <code>modelFilename</code>. We recommand deploying runtimes in their own namespace.</p> <pre><code>modelsRuntime:\n- name: \"sdruntime1\" # First runtime\n  namespace: \"sdruntime1\"\n  modelFilename: \"v1-5-pruned-emaonly.safetensors\"\n- name: \"sdruntime2\" # Second runtime\n  namespace: \"sdruntime2\"\n  modelFilename: \"v2-1_768-ema-pruned.safetensors\"\n</code></pre> <p>See <code>multiple-runtimes.yaml</code> for more reference.</p>"},{"location":"implementation-guide/deployment/configuration/#dynamic-model-runtime","title":"Dynamic Model Runtime","text":"<p>By default, models are pre-loaded to runtime. Each runtime only accept request with its model filename. You can create dynamic model runtime as a catch-all option. By enabling dynamic model runtime, a new runtime with default model <code>v1-5-pruned-emaonly.safetensors</code> is created. This runtime will accept all requests without a matching runtime. Then, the runtime will load model by request. Models should be stored in S3 bucket before sending a request with this model.</p> <pre><code>dynamicModelRuntime:\n  enabled: true # Enable dynamic model runtime by change the value to \"true\"\n  namespace: \"default\"\n</code></pre> <p>See <code>dynamic-runtime.yaml</code> for more reference.</p>"},{"location":"implementation-guide/deployment/considerations/","title":"Considerations","text":""},{"location":"implementation-guide/deployment/considerations/#deployable-regions","title":"Deployable Regions","text":"<p>The services used by this solution or the EC2 instance types may not be available in all AWS regions. Please launch this solution in an AWS region that provides the required services.</p> <p>Verified Deployable Regions</p> Region Name Verified us-east-1 us-west-2 <p>If you deploy in an unverified region, you may need to take the following actions or face potential issues:</p> <ul> <li>When deploying in a region that does not support the g5 instance type, you may need to manually specify the instance type used by Karpenter as <code>g4dn</code> or another GPU instance type.</li> <li>Performance of EFS may be affected in some regions. Refer to the Amazon EFS documentation for EFS read performance in different regions.</li> </ul>"},{"location":"implementation-guide/deployment/considerations/#iam-permissions","title":"IAM Permissions","text":"<p>Deploying this solution requires administrator or equivalent permissions.</p>"},{"location":"implementation-guide/deployment/considerations/#choose-your-stable-diffusion-runtime","title":"Choose your Stable Diffusion Runtime","text":"<p>You need runtimes to deploy the Stable Diffusion model and provide API access. Several community Stable Diffusion runtimes are available, and you can build your own runtime. Package the runtime as a container image to run it on EKS.</p> <p>Here are some examples:</p> <ul> <li>AUTOMATIC1111's Stable Diffusion Web UI</li> <li>InvokeAI</li> <li>ComfyUI</li> </ul> <p>For your convenience, you can use this sample Dockerfile to build a container image of AUTOMATIC1111's Stable Diffusion Web UI.</p>"},{"location":"implementation-guide/deployment/considerations/#important-note","title":"Important Note","text":"<ul> <li>Only one active Stable Diffusion on Amazon EKS solution stack is allowed in a region. If your deployment fails, ensure that the failed stack is deleted before attempting to redeploy.</li> </ul>"},{"location":"implementation-guide/deployment/deploy/","title":"Quick start","text":""},{"location":"implementation-guide/deployment/deploy/#provision-infrastructure-and-runtime","title":"Provision infrastructure and runtime","text":"<p>Required infrastructure and application is deployed via AWS CDK. We provide default configuration and image for quick start.</p> <p>Run the following command to clone the code:</p> <pre><code>git clone --recursive &lt;repo path&gt;\ncd stable-diffusion-on-eks\n</code></pre> <p>Before deploy, you need to edit <code>config.yaml</code> and set parameters of runtimes.</p>"},{"location":"implementation-guide/deployment/deploy/#define-model-bucket","title":"Define Model Bucket","text":"<p>Set <code>modelBucketArn</code> to the S3 bucket created on previous section.</p> <pre><code>modelBucketArn: arn:aws:s3:::&lt;bucket name&gt;\n</code></pre> <p>If you are deploying in AWS China region: <pre><code>modelBucketArn: arn:aws-cn:s3:::&lt;bucket name&gt;\n</code></pre></p>"},{"location":"implementation-guide/deployment/deploy/#define-runtime","title":"Define Runtime","text":"<p>You need to specify each runtime in <code>modelsRuntime</code> section. For each runtime, specify the following value:</p> <pre><code>modelsRuntime:\n- name: \"sdruntime\" # Name of runtime, should be unique\n  namespace: \"default\" # Namespace of runtime, suggest deploy different runtimes on seperate namespaces\n  modelFilename: \"v1-5-pruned-emaonly.safetensors\" # Model for this runtime, request will be routed by model filename.\n  type: \"SDWebUI\" # Specify type of runtime. Different type of runtime represents different API Spec.\n  extraValues:\n    sdWebuiInferenceApi:\n      inferenceApi:\n        image:\n          repository: sdoneks/inference-api # Image repository of your runtime\n          tag: latest # Image tag of your runtime\n    queueAgent:\n      image:\n        repository: sdoneks/queue-agent # Image repository for queue agent\n        tag: latest # Image tag of queue agent\n</code></pre>"},{"location":"implementation-guide/deployment/deploy/#deploy","title":"Deploy","text":"<p>Run the following command to deploy the stack:</p> <pre><code>npm install\ncdk synth\ncdk deploy --all\n</code></pre> <p>Deployment requires 20-30 minutes.</p>"},{"location":"implementation-guide/deployment/deploy/#usage","title":"Usage","text":"<p>After deployment completes, you can get endpoint and key of API on CDK output:</p> <pre><code>Outputs:\nSdOnEksDataPlaneStack.APIKey = 1234567890abcdefghij\nSdOnEksDataPlaneStack.EfsFileSystemId = fs-1234567890abcdefg\nSdOnEksDataPlaneStack.FrontApiEndpoint = https://abcdefghij.execute-api.ap-southeast-1.amazonaws.com/prod/\n...\n</code></pre> <p>Because of the service differences between AWS China regions, additional operations are required. If you use non-AWS Beijing region and Ningxia region, skip this step: Open the AWS Console, find the service Datasync, select Tasks in the left navigation bar, and select the task you just created, such as \"task-092354086086f941c\". Then click Actions - Start in the upper right corner</p> <p>You can also perform the above steps via the command line: <pre><code>aws datasync start-task-execution --task-arn=$(for taskid in $(aws datasync list-tasks --output yaml | grep TaskArn | awk '{print $2}'); do if [ \"$(aws datasync list-tags-for-resource --resource-arn $taskid --output yaml | grep -A1 stack-name | grep Value | awk '{print $2}')\" = $(cat config.yaml|grep stackName|awk '{print $2}'|sed 's/\\\"//g')\"Stack\" ]; then echo $taskid; fi; done)\n</code></pre></p> <p>You can try it out by making API call with prompt. Your request should follow API Spec of corresponding runtime. For Stable Diffusion Web UI, save the following content as a JSON file:</p> <pre><code>{\n    \"alwayson_scripts\": {\n        \"task\": \"text-to-image\",\n        \"sd_model_checkpoint\": \"v1-5-pruned-emaonly.safetensors\",\n        \"id_task\": \"123\",\n        \"uid\": \"123\",\n        \"save_dir\": \"outputs\"\n    },\n    \"prompt\": \"A dog\",\n    \"steps\": 16,\n    \"width\": 512,\n    \"height\": 512\n}\n</code></pre> <p>Now you can use <code>curl</code> to test the solutions. Copy the following cURL command and paste it into the terminal window, replacing <code>1234567890abcdefghij</code> with content of <code>SdOnEksDataPlaneStack.APIKey</code>, <code>https://abcdefghij.execute-api.ap-southeast-1.amazonaws.com/prod/</code> with the content of <code>SdOnEksDataPlaneStack.FrontApiEndpoint</code>, and <code>test.json</code> of filename you just created.</p> <pre><code>curl -X POST https://abcdefghij.execute-api.ap-southeast-1.amazonaws.com/prod/ \\\n    -H 'Content-Type: application/json' \\\n    -H 'x-api-key: 1234567890abcdefghij' \\\n    -d @test.json\n</code></pre> <p>You should get a successful response with a payload similar to the following:</p> <pre><code>{\"id_task\": \"123\", \"task\": \"text-to-image\", \"sd_model_checkpoint\": \"v1-5-pruned-emaonly.safetensors\", \"output_location\": \"s3://sdoneksdataplanestack-outputs3bucket/123\"}\n</code></pre> <p>You may need to wait for several minutes for instance launching and container starting without EBS snapshot. Once container launched and task is proceed, you can find generated image on <code>output_location</code>.</p>"},{"location":"implementation-guide/deployment/ebs-snapshot/","title":"Building EBS Snapshot","text":"<p>You can optimize launch speed by pre-caching your image as an EBS snapshot. When a new instance is launched, the data volume of the instance is pre-populated with image. When using image caching, you don't need to pull image from registry. You need to use <code>BottleRocket</code> as OS of worker node to use image caching.</p> <p>EBS snapshot should be built before deploy infrastructure. Image should be pushed to a registry (Amazon ECR) before being cached. We provided a script for building EBS snapshot.</p> <p>Run the following command to build if you have built your own image. Replace <code>us-east-1</code> to your region and <code>123456789012</code> to your AWS account 12-digit ID:</p> <pre><code>git submodule update --init --recursive\ncd utils/bottlerocket-images-cache\n./snapshot.sh 123456789012.dkr.ecr.us-east-1.amazonaws.com/sd-on-eks/inference-api:latest,123456789012.dkr.ecr.us-east-1.amazonaws.com/sd-on-eks/queue-agent:latest\n</code></pre> <p>Run the following command to build if you want to use pre-built image from Dockerhub:</p> <pre><code>git submodule update --init --recursive\ncd utils/bottlerocket-images-cache\n./snapshot.sh sdoneks/inference-api:latest,sdoneks/queue-agent:latest\n</code></pre> <p>This script will launch an instance, pull image from registry, and capture a snapshot with pulled image.</p> <p>After snapshot is built, put snapshot ID into <code>config.yaml</code>:</p> <pre><code>modelsRuntime:\n- name: \"sdruntime\"\n  namespace: \"default\"\n  modelFilename: \"v1-5-pruned-emaonly.safetensors\"\n  extraValues:\n    karpenter:\n      nodeTemplate:\n        amiFamily: Bottlerocket\n        dataVolume:\n          volumeSize: 80Gi\n          volumeType: gp3\n          deleteOnTermination: true\n          iops: 4000\n          throughput: 1000\n          snapshotID: snap-0123456789 # Change to actual snapshot ID\n</code></pre> <p>See <code>example/ebs-snapshot.yaml</code> for more reference.</p>"},{"location":"implementation-guide/deployment/image-building/","title":"Build from source","text":""},{"location":"implementation-guide/deployment/image-building/#build-image","title":"Build Image","text":"<p>You can build queue agent container image on your environment from source. <code>queue-agent</code> is for fetching message from queue and convert message to API request to Stable Diffusion Runtime.</p> <p>To build <code>queue-agent</code> image, run the following command:</p> <pre><code>docker build -t queue-agent:latest src/backend/queue_agent/\n</code></pre>"},{"location":"implementation-guide/deployment/image-building/#push-image-to-amazon-ecr","title":"Push image to Amazon ECR","text":"<p>Before pushing image, create reposirory in Amazon ECR by running the following command:</p> <pre><code>aws ecr create-repository --repository-name sd-on-eks/queue-agent\n</code></pre> <p>You can push image to Amazon ECR by running the following command. Replace <code>us-east-1</code> to your region and <code>123456789012</code> to your AWS account 12-digit ID:</p> <pre><code>aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 123456789012.dkr.ecr.us-east-1.amazonaws.com\n\ndocker tag queue-agent:latest 123456789012.dkr.ecr.us-east-1.amazonaws.com/sd-on-eks/queue-agent:latest\ndocker push 123456789012.dkr.ecr.us-east-1.amazonaws.com/sd-on-eks/queue-agent:latest\n</code></pre>"},{"location":"implementation-guide/deployment/image-building/#build-and-push-helm-chart","title":"Build and push helm chart","text":"<p>Helm chart is packaged and stored in OCI-based registry. You can store helm chart in Amazon ECR.</p> <p>Before pushing charts, create reposirory in Amazon ECR by running the following command:</p> <pre><code>aws ecr create-repository --repository-name sd-on-eks/charts/sd-on-eks\n</code></pre> <p>Package and push helm chart to Amazon ECR by running the following command. Replace <code>us-east-1</code> to your region and <code>123456789012</code> to your AWS account 12-digit ID:</p> <pre><code>helm package src/charts/sd_on_eks\nhelm push sd-on-eks-&lt;version&gt;.tgz oci://123456789012.dkr.ecr.us-east-1.amazonaws.com/sd-on-eks/charts/\n</code></pre> <p>Now your chart is stored in Amazon ECR with <code>oci://123456789012.dkr.ecr.us-east-1.amazonaws.com/sd-on-eks/charts/sd-on-eks:&lt;version&gt;</code>.</p>"},{"location":"implementation-guide/deployment/models/","title":"Create S3 bucket and store model","text":"<p>Models should be stored in S3 bucket. Stable diffusion runtime will fetch model from S3 bucket at launch.</p> <p>Create S3 bucket by running the following command. Replace <code>&lt;bucket name&gt;</code> to your desired bucket name.</p> <pre><code>aws s3api create-bucket --bucket &lt;bucket name&gt; --region us-east-1\n</code></pre> <p>You can upload model to newly created S3 bucket by running the following command:</p> <pre><code>aws s3 cp &lt;model name&gt; s3://&lt;bucket name&gt;/stable-diffusion/\n</code></pre>"},{"location":"implementation-guide/developer/source/","title":"Source code","text":"<p>Visit our GitHub repository to download the source code for this solution. The solution template is generated using the AWS Cloud Development Kit (CDK). Refer to the README.md file for more information.</p>"},{"location":"implementation-guide/observability/logging/","title":"View Logs","text":"<p>You can view the logs for this solution from CloudWatch Logs.</p> AWS Management Console <ul> <li>Open the Amazon CloudWatch console.</li> <li>In the left navigation pane, choose Logs - Log groups.</li> <li>Select the corresponding log group. The log group format is <code>/aws/eks/fluentbit-cloudwatch/workload/default</code>, replace <code>default</code> with the Kubernetes namespace where the runtime is located.</li> <li>You can select the corresponding Log Stream to view logs for different components or choose Search all log streams to search logs.</li> </ul>"},{"location":"implementation-guide/observability/monitoring/","title":"View Monitoring","text":"<p>You can view the monitoring metrics for this solution in CloudWatch.</p> <p>The monitoring metrics are provided by Container Insight. Refer to Amazon EKS and Kubernetes Container Insights metrics for metric details.</p> AWS Management Console <ul> <li>Open the Amazon CloudWatch console.</li> <li>In the left navigation pane, choose Metrics - All Metrics.</li> <li>Select ContainerInsights.</li> <li>Choose ClusterName, Namespace, PodName.</li> <li>You can view metrics for different replicas of the runtime based on PodName.</li> </ul>"},{"location":"implementation-guide/operation/kubernetes-cluster/","title":"Kubernetes Cluster Management","text":"<p>You can use the <code>kubectl</code> command to connect to the cluster created by the solution, retrieve the current system status, and make customizations.</p>"},{"location":"implementation-guide/operation/kubernetes-cluster/#install-kubectl","title":"Install kubectl","text":"<p>Refer to the Installing or updating kubectl documentation to install the <code>kubectl</code> command-line tool. Install a version of kubectl that is compatible with Kubernetes 1.27.</p>"},{"location":"implementation-guide/operation/kubernetes-cluster/#log-in-to-the-kubernetes-cluster","title":"Log in to the Kubernetes Cluster","text":"<p>You can find the command to connect to the EKS cluster from the CloudFormation output:</p> AWS Management ConsoleAWS CLI <ul> <li>Go to the AWS CloudFormation console</li> <li>Choose Stacks</li> <li>In the list, select SdOnEKSStack (or your custom name)</li> <li>Choose Output</li> <li>Record the value of the ConfigCommand item</li> <li>Run that command in your terminal.</li> </ul> <p>Run the following command to retrieve the command:</p> <pre><code>aws cloudformation describe-stacks --stack-name SdOnEKSStack --output text --query 'Stacks[0].Outputs[?OutputKey==`ConfigCommand`].OutputValue'\n</code></pre> <p>Run that command in your terminal.</p>"},{"location":"implementation-guide/solution-overview/cost/","title":"Cost Estimation","text":"<p>Important</p> <p>The cost estimation described in this section is only an example and may vary depending on your environment.</p> <p>You will incur costs for using various Amazon Web Services when running the solution. The main factors affecting the cost of the solution include:</p> <ul> <li>Instance types and purchasing options chosen</li> <li>Volume of generated images</li> <li>Elastic scaling configurations</li> </ul>"},{"location":"implementation-guide/usage/callback/","title":"Callbacks and Notifications","text":"<p>The Stable Diffusion on Amazon EKS solution operates in an asynchronous inference mode. When an image is generated or an error occurs, the user is notified through Amazon SNS. User applications can subscribe to the SNS Topic to receive notifications when image generation is complete.</p> <p>Refer to the SNS documentation to understand the types of backends supported by SNS.</p> <p>You can find the generated SNS Topic in the CloudFormation output.</p>"},{"location":"implementation-guide/usage/controlnet/","title":"ControlNet Plugin","text":""},{"location":"implementation-guide/usage/controlnet/#request-format","title":"Request Format","text":"<pre><code>{\n    \"alwayson_scripts\": {\n        // Required, task type\n        \"task\": \"text-to-image\",\n        // Required, task ID, used for uploading result images and returning responses\n        \"id_task\": \"40521\",\n        // Required, base model name, associated with queue distribution or model switching\n        \"sd_model_checkpoint\": \"v1-5-pruned-emaonly.safetensors\",\n        // Optional, user ID\n        \"uid\": \"123\",\n        // Optional, ControlNet parameters\n        \"controlnet\": {\n            \"args\": [\n                {\n                    \"image_link\": \"https://tse3-mm.cn.bing.net/th/id/OIP-C.2Z9l9li7mrfDThPW3_LE5wHaLG?pid=ImgDet&amp;rs=1\",\n                    \"module\": \"openpose\",\n                    \"model\": \"control_v11p_sd15_openpose\",\n                    \"enabled\": true,\n                    \"weight\": 1,\n                    \"resize_mode\": \"Crop and Resize\"\n                },\n                {\n                    \"image_link\": \"https://tse3-mm.cn.bing.net/th/id/OIP-C.2Z9l9li7mrfDThPW3_LE5wHaLG?pid=ImgDet&amp;rs=1\",\n                    \"module\": \"depth_leres\",\n                    \"model\": \"control_v11f1p_sd15_depth\",\n                    \"enabled\": true,\n                    \"weight\": 0.8,\n                    \"resize_mode\": \"Crop and Resize\"\n                }\n            ]\n        }\n    },\n    // All following are official parameters, use default values or pass them directly\n    \"prompt\": \"Best Quality, 1boy, wear golden LeoArmor, solo, short brown hair, looking at viewer\",\n    \"negative_prompt\": \"nsfw\",\n    \"sampler_index\": \"DPM++ SDE Karras\",\n    \"batch_size\": 1,\n    \"steps\": 16,\n    \"cfg_scale\": 7,\n    \"n_iter\": 3,\n    \"width\": 512,\n    \"height\": 512,\n    \"seed\": -1\n}\n</code></pre>"},{"location":"implementation-guide/usage/image-to-image/","title":"Image-to-Image","text":"<p>The basic usage of Stable Diffusion involves providing a prompt and a reference image to generate an image similar to the reference.</p>"},{"location":"implementation-guide/usage/image-to-image/#request-format","title":"Request Format","text":"<pre><code>{\n    \"alwayson_scripts\": {\n        // Required, task type\n        \"task\": \"image-to-image\",\n        // Required, URL of the input image\n        \"image_link\": \"https://www.segmind.com/sd-img2img-input.jpeg\",\n        // Required, task ID, used for uploading result images and returning responses\n        \"id_task\": \"31311\",\n        // Required, base model name, associated with queue distribution or model switching\n        \"sd_model_checkpoint\": \"revAnimated_v122.safetensors\",\n        // Optional, user ID\n        \"uid\": \"456\"\n    },\n    // All following are official parameters, use default values or pass them directly\n    \"prompt\": \"A fantasy landscape, trending on artstation, mystical sky\",\n    \"steps\": 16,\n    \"width\": 512,\n    \"height\": 512\n}\n</code></pre>"},{"location":"implementation-guide/usage/image-to-image/#response-format","title":"Response Format","text":"<pre><code>{\n  \"id_task\": \"123\",\n  \"task\": \"image-to-image\",\n  \"sd_model_checkpoint\": \"v1-5-pruned-emaonly.safetensors\",\n  \"output_location\": \"s3://sdoneks-pdxstack-outputs3bucket9fe85b9f-s6khzv238u4a/123\"\n}\n</code></pre>"},{"location":"implementation-guide/usage/image-to-image/#image-retrieval","title":"Image Retrieval","text":"<p>After the image is generated, it will be stored in the S3 bucket path specified by <code>output_location</code>.</p>"},{"location":"implementation-guide/usage/lora/","title":"LoRA Fine-Tuning","text":"<p>LoRA can be directly incorporated into the prompt using <code>&lt;lora:[name]:[version]&gt;</code>.</p>"},{"location":"implementation-guide/usage/lora/#request-format","title":"Request Format","text":"<pre><code>{\n    \"alwayson_scripts\": {\n        // Required, task type\n        \"task\": \"text-to-image\",\n        // Required, task ID, used for uploading result images and returning responses\n        \"id_task\": \"40521\",\n        // Required, base model name, associated with queue distribution or model switching\n        \"sd_model_checkpoint\": \"v1-5-pruned-emaonly.safetensors\",\n        // Optional, user ID\n        \"uid\": \"123\",\n    },\n    // All following are official parameters, use default values or pass them directly\n    \"prompt\": \"&lt;lora:LeoArmor:0.9&gt;, Best Quality, 1boy, wear golden LeoArmor, solo, short brown hair, looking at viewer\",\n    \"negative_prompt\": \"nsfw\",\n    \"sampler_index\": \"DPM++ SDE Karras\",\n    \"batch_size\": 1,\n    \"steps\": 16,\n    \"cfg_scale\": 7,\n    \"n_iter\": 3,\n    \"width\": 512,\n    \"height\": 512,\n    \"seed\": -1\n}\n</code></pre>"},{"location":"implementation-guide/usage/text-to-image/","title":"Text-to-Image","text":"<p>The most basic usage of Stable Diffusion involves providing a prompt to generate a corresponding image.</p>"},{"location":"implementation-guide/usage/text-to-image/#request-format","title":"Request Format","text":"<pre><code>{\n    \"alwayson_scripts\": {\n        // Required, task type\n        \"task\": \"text-to-image\",\n        // Required, base model name, associated with queue distribution or model switching\n        \"sd_model_checkpoint\": \"v1-5-pruned-emaonly.safetensors\",\n        // Required, task ID, used for uploading result images and returning responses\n        \"id_task\": \"21123\",\n        \"uid\": \"456\",\n        \"save_dir\": \"outputs\"\n    },\n    // All following are official parameters, use default values or pass them directly\n    \"prompt\": \"A dog\",\n    \"steps\": 16,\n    \"width\": 512,\n    \"height\": 512\n}\n</code></pre>"},{"location":"implementation-guide/usage/text-to-image/#response-format","title":"Response Format","text":"<pre><code>{\n  \"id_task\": \"123\",\n  \"task\": \"text-to-image\",\n  \"sd_model_checkpoint\": \"v1-5-pruned-emaonly.safetensors\",\n  \"output_location\": \"s3://sdoneks-pdxstack-outputs3bucket9fe85b9f-s6khzv238u4a/123\"\n}\n</code></pre>"},{"location":"implementation-guide/usage/text-to-image/#image-retrieval","title":"Image Retrieval","text":"<p>After the image is generated, it will be stored in the S3 bucket path specified by <code>output_location</code>.</p>"}]}