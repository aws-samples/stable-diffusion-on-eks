{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Stable Diffusion on EKS","text":"<p>Implement a scalable and cost-effective Stable Diffusion image generation solution using serverless and container solutions on AWS</p> <p>Stable Diffusion is a popular open-source project that generates images using generative AI technology. Building a scalable and cost-effective inference solution is a common challenge faced by AWS customers. This project demonstrates how to build an end-to-end, cost-effective, and rapidly scalable asynchronous image generation architecture using serverless and container services.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Event-driven architecture</li> <li>Autoscaling based on queue length using KEDA</li> <li>Automatic EC2 instance provisioning using Karpenter</li> <li>Scale new inference nodes within 2 minutes</li> <li>Save up to 70% cost using GPU Spot instances</li> <li>Support for various community Stable Diffusion runtimes</li> </ul> <p>Migration Notice</p> <p>This project has been migrated to aws-solutions-library-samples/guidance-for-asynchronous-inference-with-stable-diffusion-on-aws This repository and docs is for archive only and no longer receives update.</p> <p>You can migrate your configuration by moving <code>config.yaml</code> to the new repository.</p> <p>Disclaimer</p> <p>This solution is for reference architecture and sample code provided to you under the MIT-0 License.</p> <p>This solution is for demonstration, proof of concept, or learning purposes only. You should not use this solution directly in your production account or for production or other critical data.</p> <p>Deploying this solution may incur AWS charges for creating or using AWS chargeable resources, such as running Amazon EC2 instances or using Amazon S3 storage.</p>"},{"location":"implementation-guide/faq/","title":"Frequently Asked Questions","text":""},{"location":"implementation-guide/faq/#general-questions","title":"General Questions","text":"<ul> <li> <p>What is the Stable Diffusion on Amazon EKS solution?</p> <p>The Stable Diffusion on Amazon EKS solution is a reference architecture for deploying Stable Diffusion on Amazon Web Services. This reference architecture is designed based on an event-driven architecture and leverages modern application services such as serverless and containers. With this solution, users can quickly deploy Stable Diffusion on Amazon Web Services for image generation inference, meeting requirements for rapid on-demand scaling, high availability, and low cost.</p> </li> <li> <p>What are the unique features of this solution?</p> <p>The Stable Diffusion on Amazon EKS solution is designed based on an event-driven architecture, utilizing KEDA for queue-length-based auto-scaling to handle high-concurrency image generation inference requests from the frontend. It also leverages Karpenter and Bottlerocket to quickly scale out new inference nodes, significantly reducing the waiting time for image generation. Additionally, this solution supports using GPU Spot instances, helping customers leverage the required compute resources for inference at a lower cost. Furthermore, the solution supports various community Stable Diffusion runtimes and provides a unified Kubernetes API for managing the underlying Amazon EKS, offering excellent openness and flexibility. Customers can also easily customize this reference architecture to meet their specific business requirements.</p> </li> <li> <p>In what scenarios is the Stable Diffusion on Amazon EKS solution more suitable?</p> <p>Compared to other solutions for using Stable Diffusion on Amazon Web Services, this solution is more suitable for workloads with high or fluctuating concurrent requests for image generation inference, or with stringent performance requirements for image generation latency. Additionally, customers who have already adopted the Kubernetes technology stack as their resource scheduling and management platform, or those with extensive customization requirements, can also benefit more from this solution.</p> </li> <li> <p>What AWS services are used in this solution?</p> <p>Please refer to the AWS Services page.</p> </li> <li> <p>How does AWS support this solution?</p> <p>This solution is provided to you by the AWS Solutions Architect team under the MIT-0 license. Currently, it only offers community support. If you encounter any bugs in the solution code or have feature suggestions, please contact us through GitHub.</p> <p>If there are any issues with the AWS product services involved in the solution, you can contact the AWS Support team based on your purchased support plan.</p> <p>The AWS Solutions Architect team can provide solution discussions, workshops, and deployment support. If you need assistance, please contact your customer team or reach out to us through this webpage.</p> </li> <li> <p>How do I deploy this solution?</p> <p>We provide a one-click deployment template based on AWS CDK, allowing you to deploy this solution in your AWS account. You can customize the deployment through various configuration options in the configuration file. You can also extend the solution after deployment.</p> </li> <li> <p>What instance types can I use?</p> <p>Currently, you can use accelerated computing instances available in the corresponding region. Based on testing, you can use instance types such as g5, g4dn, and p3. The g3 instance type is not supported due to driver issues. The inf series instance types are currently not supported. CPU instances are not recommended for image generation as they are relatively slow.</p> </li> </ul>"},{"location":"implementation-guide/release-notes/","title":"Release note","text":"Date Update Log March 2024 Version v1.0.0 released November 2023 Version v1.0.0-RC.1 released"},{"location":"implementation-guide/troubleshooting/","title":"Troubleshooting","text":"<p>The following introduces the errors or issues you may encounter when using the Stable Diffusion on Amazon EKS solution, as well as the solutions.</p>"},{"location":"implementation-guide/troubleshooting/#common-troubleshooting-methods","title":"Common Troubleshooting Methods","text":""},{"location":"implementation-guide/troubleshooting/#check-lambda-error-logs","title":"Check Lambda Error Logs","text":""},{"location":"implementation-guide/troubleshooting/#check-sns-metrics","title":"Check SNS Metrics","text":""},{"location":"implementation-guide/troubleshooting/#check-sqs-metrics","title":"Check SQS Metrics","text":""},{"location":"implementation-guide/troubleshooting/#check-karpenter-logs","title":"Check Karpenter Logs","text":""},{"location":"implementation-guide/troubleshooting/#check-runtime-logs","title":"Check Runtime Logs","text":""},{"location":"implementation-guide/troubleshooting/#deployment-issues","title":"Deployment Issues","text":""},{"location":"implementation-guide/troubleshooting/#how-do-i-modify-the-default-number-of-replicas","title":"How do I modify the default number of replicas?","text":""},{"location":"implementation-guide/troubleshooting/#how-do-i-update-the-runtime","title":"How do I update the runtime?","text":""},{"location":"implementation-guide/troubleshooting/#runtime-issues","title":"Runtime Issues","text":""},{"location":"implementation-guide/troubleshooting/#unable-to-send-requests-returning-not-authorized","title":"Unable to send requests, returning Not Authorized","text":""},{"location":"implementation-guide/troubleshooting/#unable-to-send-requests-returning-400","title":"Unable to send requests, returning 400","text":""},{"location":"implementation-guide/troubleshooting/#request-sent-successfully-but-nothing-found","title":"Request sent successfully, but nothing found","text":""},{"location":"implementation-guide/troubleshooting/#request-sent-successfully-but-only-out-file-found","title":"Request sent successfully, but only .out file found","text":""},{"location":"implementation-guide/troubleshooting/#submit-issues","title":"Submit Issues","text":""},{"location":"implementation-guide/uninstall/","title":"Delete Solution","text":"<p>The deployed solution can be deleted using CloudFormation.</p> <p>Permanent Deletion</p> <p>All deleted resources will be permanently deleted and cannot be recovered by any means.</p>"},{"location":"implementation-guide/uninstall/#deletion-scope","title":"Deletion Scope","text":"<ul> <li> <p>The following will be permanently deleted:</p> <ul> <li>Amazon EKS cluster and all worker nodes</li> <li>SNS topics and all subscriptions</li> <li>SQS queues</li> <li>VPC</li> <li>IAM roles used by the solution</li> </ul> </li> <li> <p>The following will not be deleted:</p> <ul> <li>S3 bucket storing output images</li> <li>S3 bucket storing models</li> </ul> </li> </ul>"},{"location":"implementation-guide/uninstall/#preparation-before-deletion","title":"Preparation Before Deletion","text":"<p>Before deleting the solution, please ensure that the solution meets the following conditions:</p> <ul> <li>All SQS queues have been emptied</li> <li>No additional policies are attached to any IAM roles</li> <li>No additional resources (such as EC2, ENI, Cloud9, etc.) exist in the VPC</li> </ul>"},{"location":"implementation-guide/uninstall/#delete-solution_1","title":"Delete Solution","text":"<p>You can delete this solution via the CDK CLI or the AWS Management Console.</p> AWS Management ConsoleAWS CDK <ul> <li>Go to the AWS CloudFormation Console</li> <li>Select Stacks</li> <li>In the list, select sdoneksStack (or your custom name)</li> <li>Select Delete, and in the pop-up dialog, select Delete</li> </ul> <p>In the solution source code directory, run the following command to delete the solution:</p> <pre><code>npx cdk destroy\n</code></pre> <p>Deleting the solution will take approximately 20-30 minutes.</p>"},{"location":"implementation-guide/architecture/architecture/","title":"Architecture Overview","text":""},{"location":"implementation-guide/architecture/architecture/#architecture-diagram","title":"Architecture Diagram","text":""},{"location":"implementation-guide/architecture/architecture/#components","title":"Components","text":"<p>The solution consists of 3 main components:</p> <ul> <li>Serverless task scheduling and dispatching</li> <li>Stable Diffusion runtime based on Amazon EKS and Amazon EC2</li> <li>Management and maintenance components</li> </ul>"},{"location":"implementation-guide/architecture/architecture/#task-scheduling-and-dispatching","title":"Task Scheduling and Dispatching","text":"<p>This component includes an API endpoint based on Amazon API Gateway, and a task dispatching part based on Amazon SNS and Amazon SQS.</p> <ul> <li>Users send requests (model, prompt, etc.) to the API endpoint provided by Amazon API Gateway</li> <li>Requests are validated by Amazon Lambda and published to an Amazon SNS topic</li> <li>Amazon SNS publishes the requests to the corresponding SQS queue based on the runtime name specified in the request</li> </ul>"},{"location":"implementation-guide/architecture/architecture/#stable-diffusion-runtime","title":"Stable Diffusion Runtime","text":"<p>This component includes a Stable Diffusion runtime based on Amazon EKS, which supports elastic scaling based on requests.</p> <p>For each runtime:</p> <ul> <li>Upon deployment, each runtime has a dedicated Amazon SQS queue to receive requests</li> <li>The Queue Agent receives tasks from the Amazon SQS queue and sends them to the Stable Diffusion runtime to generate images</li> <li>The generated images are stored by the Queue Agent in an Amazon S3 bucket, and a completion notification is published to an Amazon SNS topic</li> <li>When there are too many messages queued in the Amazon SQS queue, KEDA will scale out the runtime replicas based on the number of messages in the queue, and Karpenter will launch new GPU instances to host the new replicas.</li> <li>When there are no more messages queued in the Amazon SQS queue, KEDA will scale in the replicas, and Karpenter will terminate unnecessary GPU instances to save costs.</li> </ul>"},{"location":"implementation-guide/architecture/architecture/#management-and-maintenance","title":"Management and Maintenance","text":"<p>This solution provides comprehensive observability and management components:</p> <ul> <li>Metrics monitoring and logging based on CloudWatch</li> <li>End-to-end tracing based on AWS X-Ray</li> <li>Infrastructure as Code deployment using AWS CDK</li> </ul>"},{"location":"implementation-guide/architecture/services-in-this-solution/","title":"AWS Services in the solution","text":"<p>The following AWS services are included in this solution:</p> AWS Service Description Amazon S3 Used for storing models and generated images. Amazon ECR Used for storing container images required for runtime. Amazon API Gateway Used for providing API interface for external access. AWS Lambda Used for request validation and routing. Amazon SQS Used for storing pending tasks. Amazon SNS Used for routing tasks to different SQS queues, and providing notification and callback upon completion. Amazon EKS Used for managing and running Stable Diffusion runtime. Amazon EC2 Used for running Stable Diffusion runtime. Amazon CloudWatch Used for monitoring system health, providing metrics monitoring, logging and tracing. AWS CDK Used for deploying and updating this solution."},{"location":"implementation-guide/deployment/","title":"Overview","text":"<p>Before deploying the solution, we recommend that you review the architecture diagram and regional support information in this guide, and then follow the instructions below to configure and deploy the solution to your account.</p>"},{"location":"implementation-guide/deployment/#prerequisites","title":"Prerequisites","text":"<p>Check all considerations in the Deployment Planning document.</p>"},{"location":"implementation-guide/deployment/#deployment-steps","title":"Deployment Steps","text":"<p>We provide a one-click deployment script to get started quickly. The total deployment time is approximately 30 minutes.</p>"},{"location":"implementation-guide/deployment/#get-the-source-code","title":"Get the Source Code","text":"<p>Run the following command to get the source code and deployment script:</p> <pre><code>git clone --recursive https://github.com/aws-samples/stable-diffusion-on-eks\ncd stable-diffusion-on-eks\n</code></pre>"},{"location":"implementation-guide/deployment/#one-click-deployment","title":"One-Click Deployment","text":"<p>Run the following command to deploy with the simplest setup quickly:</p> <pre><code>cd deploy\n./deploy.sh\n</code></pre> <p>The script will:</p> <ul> <li>Install necessary runtimes and tools</li> <li>Create an S3 bucket, download the base model of Stable Diffusion 1.5 from HuggingFace, and place it in the bucket</li> <li>Create an EBS snapshot containing the SD Web UI image using the sample image we provide</li> <li>Create a Stable Diffusion solution with the SD Web UI runtime</li> </ul> <p>Warning</p> <p>The configuration file generated by this script is the simplest configuration, containing only 1 runtime, and cannot be customized (such as scaling thresholds, custom models, custom images, etc.). If you need to customize the configuration, please run the following command:</p> <pre><code>./deploy.sh -d\n</code></pre> <p>This parameter will make the deployment script complete the pre-deployment preparation only, but not actually deploy. You can modify the configuration according to the Configuration, and then run the following command to deploy:</p> <pre><code>cdk deploy --no-rollback --require-approval never\n</code></pre>"},{"location":"implementation-guide/deployment/#deployment-parameters","title":"Deployment Parameters","text":"<p>The script provides some parameters for you to customize the deployed solution:</p> <ul> <li><code>-h, --help</code>: Show help information</li> <li><code>-n, --stack-name</code>: Customize the name of the deployed solution, affecting the naming of generated resources. Default is <code>sdoneks</code>.</li> <li><code>-R, --region</code>: The region where the solution is deployed. Default is the region of the current AWS configuration profile.</li> <li><code>-d, --dry-run</code>: Generate configuration files only, do not deploy.</li> <li><code>-b, --bucket</code>: Specify the name of an existing S3 bucket to store the model. The S3 bucket must already exist and be in the same region as the solution. You can manually create the S3 bucket according to this document.</li> <li><code>-s, --snapshot</code>: Specify an existing EBS snapshot ID. You can build the EBS snapshot yourself according to this document.</li> <li><code>-r, --runtime-name</code>: Specify the name of the deployed runtime, affecting the name used when calling the API. Default is <code>sdruntime</code>.</li> <li><code>-t, --runtime-type</code>: Specify the type of the deployed runtime, only accepting <code>sdwebui</code> and <code>comfyui</code>. Default is <code>sdwebui</code>.</li> </ul>"},{"location":"implementation-guide/deployment/#manual-deployment","title":"Manual Deployment","text":"<p>You can also deploy this solution on AWS manually without using the script by following these steps:</p> <ol> <li>Create an Amazon S3 model bucket and store the required models in the bucket</li> <li>(Optional) Build the container image</li> <li>(Optional) Store the container image in an EBS cache to accelerate startup</li> <li>Deploy and launch the solution stack</li> </ol>"},{"location":"implementation-guide/deployment/aws-cn/","title":"Deploying in AWS China Regions","text":"<p>This solution supports deployment in AWS China Regions.</p> Region Name Validated China (Ningxia) <p>However, due to the special network environment in China, the following limitations will apply:</p> <ul> <li>The default <code>g5</code> instance type is not supported in China regions. You need to manually specify the instance type used by Karpenter to be <code>g4dn</code> or other GPU instance types.</li> <li>You need to build container images yourself, or copy the standard images to ECR in the China region. It is not recommended to use images from ECR Public.</li> <li>Some component Helm Charts are hosted on Github, and there may be a chance that they cannot be retrieved when deploying in China regions, and you need to retry.</li> <li>Models cannot be automatically downloaded from Hugging Face or Github, and you need to manually download the models and upload them to an S3 bucket.</li> </ul>"},{"location":"implementation-guide/deployment/aws-cn/#steps-for-deploying-in-china-regions","title":"Steps for Deploying in China Regions","text":"<p>The steps for deploying in AWS China Regions are different from the normal deployment process, and you should follow these steps:</p> <ol> <li>Build or transfer images to ECR</li> <li>Download models and store them in an S3 bucket</li> <li>Create an EBS disk snapshot</li> <li>Generate and modify configuration files</li> <li>Proceed with deployment</li> </ol>"},{"location":"implementation-guide/deployment/aws-cn/#build-or-transfer-images-to-ecr","title":"Build or Transfer Images to ECR","text":"<p>Since the default container images are stored in ECR Public, you may experience slow speeds or connection interruptions when pulling images or creating image caches. We recommend that you build the images yourself or transfer the existing images to your ECR image repository.</p> <p>If you need to build the images yourself, please refer to the Image Building documentation.</p> <p>If you need to transfer pre-built images to ECR in the China region, you can run the following commands on an instance with Docker installed and ECR permissions:</p> <pre><code>docker pull public.ecr.aws/bingjiao/sd-on-eks/sdwebui:latest\ndocker pull public.ecr.aws/bingjiao/sd-on-eks/comfyui:latest\ndocker pull public.ecr.aws/bingjiao/sd-on-eks/queue-agent:latest\n\naws ecr create-repository --repository-name sd-on-eks/sdwebui\naws ecr create-repository --repository-name sd-on-eks/comfyui\naws ecr create-repository --repository-name sd-on-eks/queue-agent\n\ndocker tag public.ecr.aws/bingjiao/sd-on-eks/sdwebui:latest 123456789012.dkr.ecr.cn-northwest.amazonaws.com.cn/sd-on-eks/sdwebui:latest\ndocker tag public.ecr.aws/bingjiao/sd-on-eks/comfyui:latest 123456789012.dkr.ecr.cn-northwest.amazonaws.com.cn/sd-on-eks/comfyui:latest\ndocker tag public.ecr.aws/bingjiao/sd-on-eks/queue-agent:latest 123456789012.dkr.ecr.cn-northwest.amazonaws.com.cn/sd-on-eks/queue-agent:latest\n\naws ecr get-login-password --region cn-northwest-1 | docker login --username AWS --password-stdin 123456789012.dkr.ecr.cn-northwest-1.amazonaws.com.cn\n\ndocker push 123456789012.dkr.ecr.cn-northwest.amazonaws.com.cn/sd-on-eks/sdwebui:latest\ndocker push 123456789012.dkr.ecr.cn-northwest.amazonaws.com.cn/sd-on-eks/comfyui:latest\ndocker push 123456789012.dkr.ecr.cn-northwest.amazonaws.com.cn/sd-on-eks/queue-agent:latest\n</code></pre> <p>We recommend that you follow the instructions in the Image Building documentation to place the Helm Chart in ECR or an HTTP server.</p>"},{"location":"implementation-guide/deployment/aws-cn/#download-models-and-store-them-in-an-s3-bucket","title":"Download Models and Store Them in an S3 Bucket","text":"<p>Since Hugging Face cannot be accessed smoothly in China, please download the models from other image sites and upload them to an S3 bucket following the instructions in the Model Storage documentation.</p>"},{"location":"implementation-guide/deployment/aws-cn/#create-an-ebs-disk-snapshot","title":"Create an EBS Disk Snapshot","text":"<p>Please follow the instructions in the Image Cache Building documentation to create an EBS disk snapshot to accelerate image loading.</p>"},{"location":"implementation-guide/deployment/aws-cn/#generate-and-modify-configuration-files","title":"Generate and Modify Configuration Files","text":"<p>Run the following command to install the tools and generate the initial configuration files:</p> <pre><code>cd deploy\n./deploy.sh -b &lt;bucket name&gt; -s &lt;snapshot ID&gt; -d\n</code></pre> <p>This command will generate a <code>config.yaml</code> template in the parent directory, but this template needs to be edited for deployment in the China region. Edit this file and add the following content:</p> <pre><code>stackName: sdoneks\nmodelBucketArn: arn:aws-cn:s3:::${MODEL_BUCKET}  # Change aws to aws-cn in this ARN\nAPIGW:\n  stageName: dev\n  throttle:\n    rateLimit: 30\n    burstLimit: 50\nmodelsRuntime:\n- name: sdruntime\n  namespace: \"default\"\n  modelFilename: \"v1-5-pruned-emaonly.safetensors\"\n  dynamicModel: false\n  # chartRepository: \"http://example.com/\" # If you host the Helm Chart yourself, uncomment this line and change the value to the address of the Helm Chart (oci:// or http://), otherwise delete this line.\n  type: sdwebui\n  extraValues:\n    runtime:\n      inferenceApi:\n        image:\n          repository: 123456789012.dkr.ecr.cn-northwest-1.amazonaws.com.cn/sd-on-eks/sdwebui # Change this to the address of your ECR image repository\n          tag: latest\n      queueAgent:\n        image:\n          repository: 123456789012.dkr.ecr.cn-northwest-1.amazonaws.com.cn/sd-on-eks/queue-agent # Change this to the address of your ECR image repository\n          tag: latest\n    karpenter:\n      nodeTemplate:\n        amiFamily: Bottlerocket\n        dataVolume:\n          volumeSize: 80Gi\n          volumeType: gp3\n          deleteOnTermination: true\n          iops: 4000\n          throughput: 1000\n          snapshotID: snap-1234567890 # The EBS snapshot ID will be automatically filled in here\n      provisioner:\n        instanceType:\n        - \"g5.xlarge\"\n        - \"g4dn.xlarge\"\n        - \"g5.2xlarge\"\n        - \"g4dn.2xlarge\"\n        capacityType:\n          onDemand: true\n          spot: true\n      scaling:\n        queueLength: 10\n        minReplicaCount: 0\n        maxReplicaCount: 5\n        cooldownPeriod: 300\n</code></pre> <p>After completing the above steps, you can run the deployment command:</p> <pre><code>cdk deploy --no-rollback --require-approval never\n</code></pre>"},{"location":"implementation-guide/deployment/configuration/","title":"Configuration","text":""},{"location":"implementation-guide/deployment/configuration/#solution-configuration","title":"Solution Configuration","text":"<p>This solution can be configured via <code>config.yaml</code>. If you want to use a configuration file with a different name or path, please specify the <code>CDK_CONFIG_PATH</code> environment variable.</p> <p>The following table lists the configuration parameters and their default values for the CDK template:</p> Parameter Description Required Default <code>stackName</code> Name of the stack. The name will be added as a prefix of all resource names. Yes <code>sdoneks</code> <code>modelBucketArn</code> S3 bucket for model storage. Models file should be populated into the bucket. This parameter applies to all runtimes. Yes <code>\"\"</code> <code>modelsRuntime</code> Define Stable diffusion runtime. At least one runtime should be defined. Yes See definition below <code>modelsRuntime.name</code> Name of individual Stable diffusion runtime. Yes <code>sdruntime</code> <code>modelsRuntime.namespace</code> Namespace of individual Stable diffusion runtime. Namespace will be created if not exists. Yes <code>default</code> <code>modelsRuntime.type</code> Type of individual Stable diffusion runtime. Currently only <code>sdwebui</code> or <code>confyui</code> are supported. Yes <code>sdwebui</code> <code>modelsRuntime.chartRepository</code> Override default helm chart repository. Protocol (<code>oci://</code> or <code>https://</code>)should be added as a prefix of repository. (Default: <code>https://aws-samples.github.io/stable-diffusion-on-eks/charts/</code>) No N/A <code>modelsRuntime.chartVersion</code> Override version of helm chart. (Default: 1.0.0) No N/A <code>modelsRuntime.modelFilename</code> (For SD Web UI only) Filename of model using in the runtime. Filename should be in <code>.ckpt</code> or <code>.safetensors</code> format. Filename should be quoted if contains number only. No <code>v1-5-pruned-emaonly.safetensors</code> <code>modelsRuntime.dynamicModel</code> (For SD Web UI only) Switch to allow model be loaded by request. No <code>false</code> <code>modelsRuntime.extraValues</code> Extra parameter passed to the runtime. See values definition for detail. No N/A"},{"location":"implementation-guide/deployment/configuration/#runtime-configuration","title":"Runtime Configuration","text":"<p>Stable diffusion runtimes are deployed via Helm Charts. You can configure individual runtime parameters via <code>modelsRuntime.extraValues</code>.</p> <p>Please note that some parameters marked as <code>Populated by CDK</code> cannot be changed, as their values are automatically generated by CDK, and any manually set values will be overridden.</p> Parameter Description Default Global <code>global.awsRegion</code> AWS region where the stack resides. Not changable. Populated by CDK <code>global.stackName</code> Name of CDK stack. Not changable. Populated by CDK Karpenter Provisioner <code>karpenter.provisioner.labels</code> Labels applied to all nodes. Should be in key-values format. <code>{}</code> <code>karpenter.provisioner.capacityType.onDemand</code> Allow Karpenter to launch on-demand node. <code>true</code> <code>karpenter.provisioner.capacityType.spot</code> Allow Karpenter to create spot node. When <code>provisioner.capacityType.onDemand</code> is true, Karpenter will priortize launching Spot instance. <code>true</code> <code>karpenter.provisioner.instanceType</code> An array of instance types Karpenter can launch. Should only include instance type available in current region. <code>- \"g5.xlarge\"</code> <code>karpenter.provisioner.extraRequirements</code> Additional requirement for Karpenter to choose instance type. <code>[]</code> <code>karpenter.provisioner.extraTaints</code> Provisioned nodes will have <code>nvidia.com/gpu:NoSchedule</code> and <code>runtime:NoSchedule</code> taints by default. Use this paremeter for additional taints. <code>[]</code> <code>karpenter.provisioner.resourceLimits</code> Resource limits prevent Karpenter from creating new instances once the limit is exceeded. <code>cpu</code>, <code>memory</code> and <code>nvidia.com/gpu</code> are supported. <code>nvidia.com/gpu: 100</code> <code>karpenter.provisioner.consolidation</code> Enables consolidation which attempts to removing un-needed nodes and down-sizing those that can't be removed. <code>true</code> Karpenter Node Template <code>karpenter.nodeTemplate.securityGroupSelector</code> Tagged security groups will be attached to instances. Not changable. Populated by CDK <code>karpenter.nodeTemplate.subnetSelector</code> Instances will be launched in tagged subnets. Not changable. Populated by CDK <code>karpenter.nodeTemplate.tags</code> Tags applied to all nodes. Should be in key-values format. <code>{}</code> <code>karpenter.nodeTemplate.amiFamily</code> OS option for worker nodes. Karpenter will automatically query for the appropriate EKS optimized AMI via AWS Systems Manager (SSM). <code>AL2</code> and <code>Bottlerocket</code> are supported. <code>Bottlerocket</code> <code>karpenter.nodeTemplate.osVolume</code> Control the Elastic Block Storage (EBS) volumes that Karpenter attaches to provisioned nodes. See this for schema. This volume will be attached to <code>/dev/xvda</code>. <code>karpenter.nodeTemplate.dataVolume</code> Control the Elastic Block Storage (EBS) volumes that Karpenter attaches to provisioned nodes. See this for schema. This volume will be attached to <code>/dev/xvdb</code>. Required when using <code>Bottlerocket</code>. <code>karpenter.nodeTemplate.userData</code> UserData that is applied to your worker nodes. See the examples here for format. <code>\"\"</code> runtime <code>runtime.labels</code> Labels applied to all resources. Should be in key-values format. <code>\"\"</code> <code>runtime.annotations</code> Annotations applied to stable diffusion runtime. Should be in key-values format. <code>\"\"</code> <code>runtime.serviceAccountName</code> Name of service account used by runtime. Not changable. Populated by CDK <code>runtime.replicas</code> Replica count of runtime. <code>1</code> <code>runtime.scaling.enabled</code> Enable auto scaling by SQS length. <code>true</code> <code>runtime.scaling.queueLength</code> Target value for queue length. KEDA will scale pod to <code>ApproximateNumberOfMessage / queueLength</code> replicas. <code>10</code> <code>runtime.scaling.cooldownPeriod</code> The period (in seconds) to wait after the last trigger reported active before scaling the resource back to <code>minReplicaCount</code>. <code>60</code> <code>runtime.scaling.maxReplicaCount</code> This setting is passed to the HPA definition that KEDA will create for a given resource and holds the maximum number of replicas of the target resource. <code>20</code> <code>runtime.scaling.minReplicaCount</code> Minimum number of replicas KEDA will scale the resource down to. <code>0</code> <code>runtime.scaling.pollingInterval</code> Interval (in seconds) to check each trigger on. <code>1</code> <code>runtime.scaling.scaleOnInFlight</code> When set to <code>true</code>, not visible (in-flight) messages will be counted in <code>ApproximateNumberOfMessage</code> <code>false</code> <code>runtime.scaling.extraHPAConfig</code> KEDA would feed values from this section directly to the HPA's <code>behavior</code> field. Follow Kubernetes documentation for details. <code>{}</code> Stable Diffusion Runtime <code>runtime.inferenceApi.image.repository</code> Image Repository of Runtime. <code>public.ecr.aws/bingjiao/sd-on-eks/sdwebui</code> <code>runtime.inferenceApi.image.tag</code> Image tag of Runtime. <code>latest</code> <code>runtime.inferenceApi.modelFilename</code> Model filename of Runtime. Not changable. Populated by CDK <code>runtime.inferenceApi.extraEnv</code> Extra environment variable for Runtime. Should be in Kubernetes format. <code>{}</code> <code>runtime.inferenceApi.modelMountPath</code> Path for model folder inside container. <code>/opt/ml/code/models</code> <code>runtime.inferenceApi.commandArguments</code> Additional arguments passed to runtime. <code>\"\"</code> <code>runtime.inferenceApi.resources</code> Resource request and limit for Runtime. Queue Agent <code>runtime.queueAgent.image.repository</code> Image Repository of queue agent. <code>sdoneks/queue-agent</code> <code>runtime.queueAgent.image.tag</code> Image tag of queue agent. <code>latest</code> <code>runtime.queueAgent.extraEnv</code> Extra environment variable for queue agent. Should be in Kubernetes format. <code>{}</code> <code>runtime.queueAgent.dynamicModel</code> Enable model switch by request. Not changable. Populated by CDK <code>runtime.queueAgent.s3Bucket</code> S3 bucket for generated image. Not changable. Populated by CDK <code>runtime.queueAgent.snsTopicArn</code> SNS topic for image generate complete notification. Not changable. Populated by CDK <code>runtime.queueAgent.sqsQueueUrl</code> SQS queue URL of job queue. Not changable. Populated by CDK <code>runtime.queueAgent.resources</code> Resource request and limit for queue agent. <code>runtime.queueAgent.XRay.enabled</code> Enable X-ray tracing agent for queue agent. <code>true</code> Persistence <code>runtime.persistence.enabled</code> Enable presistence of model stroage. <code>true</code> <code>runtime.persistence.labels</code> Labels applied to presistence volume. Should be in key-values format. <code>{}</code> <code>runtime.persistence.annotations</code> Annotations applied to presistence volume. Should be in key-values format. <code>{}</code> <code>runtime.persistence.storageClass</code> Storage class for model storage <code>s3-model-storage-sc</code> <code>runtime.persistence.size</code> Size of persistence volume. <code>2Ti</code> <code>runtime.persistence.accessModes</code> Access mode of persistence volume. <code>ReadWriteMany</code>"},{"location":"implementation-guide/deployment/considerations/","title":"Deployment Planning","text":"<p>Please check the following considerations before deployment:</p>"},{"location":"implementation-guide/deployment/considerations/#deployable-regions","title":"Deployable Regions","text":"<p>The services used in this solution, or the Amazon EC2 instance types, may not be available in all AWS Regions at this time. Please launch this solution in an AWS Region that provides the required services.</p> <p>Verified Deployable Regions</p> Region Name Verified US East (N. Virginia) US West (Oregon) <p>If you deploy in an unverified region, you may need to handle the following or face the following issues:</p> <ul> <li>When deploying in regions that do not support <code>g5</code> instance types, you need to manually specify the instance type used by Karpenter as <code>g4dn</code> or other GPU instance types.</li> </ul> <p>Deploying in AWS China Regions</p> <p>Please refer to Deploying in AWS China Regions</p>"},{"location":"implementation-guide/deployment/considerations/#iam-permissions","title":"IAM Permissions","text":"<p>Deploying this solution requires administrator or equivalent permissions. Due to the number of components involved, we do not provide a minimal permissions list.</p>"},{"location":"implementation-guide/deployment/considerations/#service-quotas","title":"Service Quotas","text":"<p>Each AWS account in each AWS Region has quotas on the number of resources you can create. You can view your service quotas using the Service Quota tool in the AWS console. If a service quota can be increased, you can request an increase through the tool by opening a case.</p> <p>The main service quotas related to this solution are:</p> AWS Service Quota Entry Estimated Usage Adjustable Amazon EC2 Running On-Demand G and VT instances Based on max concurrent GPU instances Amazon EC2 All G and VT Spot Instance Requests Based on max concurrent GPU instances Amazon SNS Messages Published per Second Based on max concurrent requests <p>In addition, you need to consider the following service quotas during deployment:</p> AWS Service Quota Entry Estimated Usage Adjustable Amazon VPC VPCs per Region 1 Amazon VPC NAT gateways per Availability Zone 1 Amazon EC2 EC2-VPC Elastic IPs 1 Amazon S3 General purpose buckets 1 per queue"},{"location":"implementation-guide/deployment/considerations/#choosing-a-stable-diffusion-runtime","title":"Choosing a Stable Diffusion Runtime","text":"<p>You need a runtime to deploy the Stable Diffusion model and provide API access.</p> <p>Currently, there are multiple community Stable Diffusion runtimes available:</p> Runtime Name Link Verified Stable Diffusion Web UI GitHub ComfyUI GitHub InvokeAI GitHub <p>You can also choose other runtimes or build your own runtime. You need to package the runtime as a container image to run it on EKS.</p> <p>You need to fully understand and comply with the license terms of the Stable Diffusion runtime you are using.</p> <p>Example Runtime</p> <p>You can use the community-provided example Dockerfile to build the runtime container images for Stable Diffusion Web UI and ComfyUI. Please note that this image is only for technical evaluation and testing purposes, and should not be deployed to production environments.</p> <p>Model Storage</p> <p>By default, this solution will load the model to the <code>/opt/ml/code/models</code> directory, please ensure your runtime is configured to read the model from this directory.</p> <p>You need to disable mmap to achieve the highest performance for your runtime.</p> <ul> <li>For SD Web UI, you need to set <code>disable_mmap_load_safetensors: true</code> in <code>config.json</code></li> <li>For ComfyUI, you need to manually modify the source code as guided in the community issue.</li> </ul> <p>Notes on SD Web UI Runtime</p> <p>For the SD Web UI runtime, depending on the model being run, the runtime can be either a static runtime (pre-loading the model) or a dynamic runtime (loading the model on-demand).</p> <ul> <li>Static runtime requires specifying the model to be used in <code>modelFilename</code>. This model will be loaded into GPU memory at startup.</li> <li>Dynamic runtime requires specifying <code>dynamicModel: true</code>. In this case, there is no need to specify the model in advance. The runtime will load the model from Amazon S3 and perform model inference based on the model used in the request.</li> </ul>"},{"location":"implementation-guide/deployment/considerations/#other-important-notes-and-limitations","title":"Other Important Notes and Limitations","text":"<ul> <li> <p>In the current version, this solution will automatically create a new VPC when deployed. This VPC includes:</p> <ul> <li>CIDR <code>10.0.0.0/16</code></li> <li>3 public subnets distributed across different Availability Zones, with subnet size <code>/19</code></li> <li>3 private subnets distributed across different Availability Zones, with subnet size <code>/19</code></li> <li>3 NAT gateways (placed in public subnets)</li> <li>1 Internet gateway</li> <li>Corresponding route tables and security groups</li> </ul> <p>Currently, the parameters of this VPC cannot be customized.</p> </li> <li> <p>In the current version, this solution can only be deployed on a newly created EKS cluster, and the version is fixed at <code>1.28</code>. We will update the cluster version as Amazon EKS releases new versions.</p> </li> </ul>"},{"location":"implementation-guide/deployment/deploy/","title":"Manual Deployment","text":"<p>Follow these steps to deploy this solution:</p>"},{"location":"implementation-guide/deployment/deploy/#install-prerequisites","title":"Install Prerequisites","text":"<p>Please install the following runtimes before deployment:</p> <ul> <li>Node.js version 18 or later</li> <li>AWS CLI</li> <li>AWS CDK Toolkit</li> <li>git</li> </ul>"},{"location":"implementation-guide/deployment/deploy/#edit-configuration-file","title":"Edit Configuration File","text":"<p>The configuration for this solution is stored in the <code>config.yaml</code> file. We provide a configuration file template that you can customize according to your actual needs.</p>"},{"location":"implementation-guide/deployment/deploy/#set-model-bucket-required","title":"Set Model Bucket (Required)","text":"<p>Replace <code>&lt;bucket name&gt;</code> in <code>modelBucketArn</code> with the name of the S3 bucket where you store the models.</p> <pre><code>modelBucketArn: arn:aws:s3:::&lt;bucket name&gt;\n</code></pre> <p>China Regions</p> <p>If you are using an AWS China Region, ensure that the partition in the ARN is <code>aws-cn</code>.</p> <pre><code>modelBucketArn: arn:aws-cn:s3:::&lt;bucket name&gt;\n</code></pre>"},{"location":"implementation-guide/deployment/deploy/#set-stable-diffusion-runtime-required","title":"Set Stable Diffusion Runtime (Required)","text":"<p>You need to specify the parameters for the runtime. The runtime is defined in <code>modelsRuntime</code> as follows:</p> <pre><code>modelsRuntime:\n- name: \"sdruntime\" # Required parameter, the name of the runtime, cannot be the same as other runtimes\n  namespace: \"default\" # Required parameter, the Kubernetes namespace where the runtime is located, it is not recommended to place it in the same namespace as other runtimes.\n  type: \"sdwebui\" # Required parameter, the type of this runtime, currently only \"sdwebui\" and \"comfyui\" are supported\n  modelFilename: \"v1-5-pruned-emaonly.safetensors\" # (SD Web UI) The name of the model used by this runtime, cannot be the same as other runtimes.\n  dynamicModel: false # (SD Web UI) Whether this runtime allows dynamic model loading.\n</code></pre> <p>You can configure multiple runtimes in the <code>modelsRuntime</code> section.</p>"},{"location":"implementation-guide/deployment/deploy/#set-custom-image-optional","title":"Set Custom Image (Optional)","text":"<p>If you have built your own image and/or Helm Chart, you need to specify the image in the corresponding runtime as follows:</p> <pre><code>modelsRuntime:\n- name: \"sdruntime\"\n  namespace: \"default\"\n  type: \"sdwebui\"\n  modelFilename: \"v1-5-pruned-emaonly.safetensors\"\n  dynamicModel: false\n  chartRepository: \"\" # Optional parameter, if you have built a Helm Chart, you need to fill in the address where the Chart is located. It should include the protocol prefix (oci:// or https://)\n  chartVersion: \"\" # Optional parameter, if you have built a Helm Chart, you need to fill in the version of the Chart\n  extraValues: # Add the following\n    runtime:\n      inferenceApi:\n        image:\n          repository: &lt;account_id&gt;.dkr.ecr.&lt;region&gt;.amazonaws.com/sd-on-eks/sdwebui # The address of the Stable Diffusion runtime image.\n          tag: latest # The tag of the image\n      queueAgent:\n        image:\n          repository: &lt;account_id&gt;.dkr.ecr.&lt;region&gt;.amazonaws.com/sd-on-eks/queue-agent # The address of the Queue agent image.\n          tag: latest # The tag of the image\n</code></pre>"},{"location":"implementation-guide/deployment/deploy/#set-ebs-snapshot-based-image-cache-optional","title":"Set EBS Snapshot-based Image Cache (Optional)","text":"<p>If you have built an EBS snapshot-based image cache, you need to specify the snapshot ID in the corresponding runtime as follows:</p> <pre><code>modelsRuntime:\n- name: \"sdruntime\"\n  namespace: \"default\"\n  type: \"sdwebui\"\n  modelFilename: \"v1-5-pruned-emaonly.safetensors\"\n  extraValues:\n    karpenter: # Add the following\n      nodeTemplate:\n        amiFamily: Bottlerocket\n        dataVolume:\n          volumeSize: 80Gi # Do not modify to a value less than 80Gi\n          volumeType: gp3 # Do not modify\n          deleteOnTermination: true # Do not modify\n          iops: 4000 # Do not modify\n          throughput: 1000 # Do not modify\n          snapshotID: snap-0123456789 # Replace with the EBS snapshot ID\n</code></pre>"},{"location":"implementation-guide/deployment/deploy/#other-detailed-settings-optional","title":"Other Detailed Settings (Optional)","text":"<p>If you need to configure the runtime in detail, please refer to the configuration options.</p>"},{"location":"implementation-guide/deployment/deploy/#start-deployment","title":"Start Deployment","text":"<p>After completing the configuration, run the following commands to deploy:</p> <pre><code>npm install\ncdk deploy  --no-rollback --require-approval never\n</code></pre> <p>The deployment generally takes 15-20 minutes. Since the deployment is performed on the AWS side through CloudFormation, you do not need to redeploy if the CDK CLI is accidentally closed.</p>"},{"location":"implementation-guide/deployment/deploy/#next-steps","title":"Next Steps","text":"<p>After the deployment is complete, you will see the following output:</p> <pre><code>Outputs:\nsdoneksStack.GetAPIKeyCommand = aws apigateway get-api-keys --query 'items[?id==`abcdefghij`].value' --include-values --output text\nsdoneksStack.FrontApiEndpoint = https://abcdefghij.execute-api.us-east-1.amazonaws.com/prod/\nsdoneksStack.ConfigCommand = aws eks update-kubeconfig --name sdoneksStack --region us-east-1 --role-arn arn:aws:iam::123456789012:role/sdoneksStack-sdoneksStackAccessRole\n...\n</code></pre> <p>Now, you can:</p> <ul> <li>Send API requests to use Stable Diffusion to generate images</li> <li>Log in to the Kubernetes cluster for maintenance operations</li> </ul>"},{"location":"implementation-guide/deployment/ebs-snapshot/","title":"Image Cache Build","text":"<p>By pre-caching container images as EBS snapshots, you can optimize the startup speed of compute instances. When launching a new instance, the instance's data volume comes with a container image cache, eliminating the need to pull from the image repository again.</p> <p>Create the EBS snapshot before deploying the solution. We provide a script for building the EBS snapshot.</p> Using Custom ImageUsing Pre-built Image <p>If you build and push the image to Amazon ECR yourself, run the following command. Replace <code>us-east-1</code> with the region where the solution is located, and replace <code>123456789012</code> with your 12-digit AWS account:</p> <pre><code>cd utils/bottlerocket-images-cache\n./snapshot.sh 123456789012.dkr.ecr.us-east-1.amazonaws.com/sd-on-eks/sdwebui:latest,123456789012.dkr.ecr.us-east-1.amazonaws.com/sd-on-eks/queue-agent:latest\n</code></pre> <p>If you use the pre-built image provided by the solution, run the following command:</p> <pre><code>cd utils/bottlerocket-images-cache\n./snapshot.sh public.ecr.aws/bingjiao/sd-on-eks/sdwebui:latest,public.ecr.aws/bingjiao/sd-on-eks/comfyui:latest,public.ecr.aws/bingjiao/sd-on-eks/queue-agent:latest\n</code></pre> <p>After the script completes, it will output the EBS snapshot ID (in the format similar to <code>snap-0123456789</code>). You can apply this snapshot when deploying.</p> <p>For more details about this script, please refer to the GitHub repository</p>"},{"location":"implementation-guide/deployment/image-building/","title":"Image Building","text":"<p>You can build images from source code and store them in your image repository.</p> <p>Runtime Selection</p> <p>You need to provide the Stable Diffusion runtime image yourself. You can get the supported Stable Diffusion runtimes from Deployment Considerations.</p> <p>Pre-built Images</p> <p>For evaluation and testing purposes, you can use our pre-built images: <pre><code>SD Web UI: public.ecr.aws/bingjiao/sd-on-eks/sdwebui:latest\nComfyUI: public.ecr.aws/bingjiao/sd-on-eks/comfyui:latest\nQueue Agent: public.ecr.aws/bingjiao/sd-on-eks/queue-agent:latest\n</code></pre> Please note that these images are for technical evaluation and testing purposes only, and you are responsible for any licensing risks associated with using these images.</p>"},{"location":"implementation-guide/deployment/image-building/#build-images","title":"Build Images","text":"<p>Run the following command to build the <code>queue-agent</code> image:</p> <pre><code>docker build -t queue-agent:latest src/backend/queue_agent/\n</code></pre> <p>Example Runtimes</p> <p>You can use the example Dockerfile provided by the community to build the runtime container images for Stable Diffusion Web UI and ComfyUI. Please note that these images are for technical evaluation and testing purposes only and should not be deployed to production environments.</p>"},{"location":"implementation-guide/deployment/image-building/#push-images-to-amazon-ecr","title":"Push Images to Amazon ECR","text":"<p>Image Repository Selection</p> <p>We recommend using Amazon ECR as the image repository, but you can also choose other repositories that support the OCI standard, such as Harbor.</p> <p>First-time Push</p> <p>Amazon ECR requires creating the image repository before pushing.</p> AWS CLI <p>Run the following command to create: <pre><code>aws ecr create-repository --repository-name sd-on-eks/queue-agent\n</code></pre></p> <p>Run the following commands to log in to the image repository and push the image. Replace <code>us-east-1</code> with your AWS region, and <code>123456789012</code> with your AWS account ID:</p> <pre><code>aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 123456789012.dkr.ecr.us-east-1.amazonaws.com\n\ndocker tag queue-agent:latest 123456789012.dkr.ecr.us-east-1.amazonaws.com/sd-on-eks/queue-agent:latest\ndocker push 123456789012.dkr.ecr.us-east-1.amazonaws.com/sd-on-eks/queue-agent:latest\n</code></pre>"},{"location":"implementation-guide/deployment/image-building/#build-and-push-helm-chart","title":"Build and Push Helm Chart","text":"<p>The solution is deployed via a Helm Chart. The Helm Chart can be stored on any HTTP server accessible over the Internet or in an image repository compatible with the OCI standard. You can store the Helm Chart in Amazon ECR.</p> <p>China Region Support</p> <p>Due to a known issue with the CDK framework, you cannot store the Helm Chart in an ECR image repository in the China regions. We are actively working on fixing this issue.</p> <p>Pre-built Helm Chart</p> <p>In general, you do not need to deeply customize the contents of the Helm Chart. In this case, you can directly use our pre-built Helm Chart. You can configure the runtime via <code>config.yaml</code>.</p> Using ECR Image RepositoryUsing HTTP Server <p>First-time Push</p> <p>Amazon ECR requires creating the image repository before pushing.</p> AWS CLIAWS Management Console <p>Run the following command to create: <pre><code>aws ecr create-repository --repository-name sd-on-eks/charts/sd-on-eks\n</code></pre></p> <ul> <li>Open the Amazon ECR console at https://console.aws.amazon.com/ecr/.</li> <li>Choose Get started.</li> <li>For Visibility settings, choose Private.</li> <li>For Repository name, enter <code>sd-on-eks/charts/sd-on-eks</code>.</li> <li>Choose Create repository.</li> </ul> <p>Run the following commands to log in to the image repository and push the Helm Chart. Replace <code>us-east-1</code> with your AWS region, and <code>123456789012</code> with your AWS account ID:</p> <pre><code>helm package src/charts/sd_on_eks\nhelm push sd-on-eks-&lt;version&gt;.tgz oci://123456789012.dkr.ecr.us-east-1.amazonaws.com/sd-on-eks/charts/\n</code></pre> <p>After the upload is complete, you need to modify <code>config.yaml</code> and add the following content under each runtime that needs to use this Helm Chart:</p> <pre><code>modelsRuntime:\n- name: sdruntime\n  namespace: default\n  type: sdwebui\n  chartRepository: \"oci://123456789012.dkr.ecr.us-east-1.amazonaws.com/sd-on-eks/charts/\"\n  chartVersion: \"1.0.0\" # Modify if you customize the Helm Chart version\n</code></pre> <p>Access Control</p> <p>Make sure the HTTP server is open to the Internet and does not have any access control (such as IP whitelisting) set up.</p> <p>Run the following command to package the Helm Chart:</p> <pre><code>helm package src/charts/sd_on_eks\n</code></pre> <p>After packaging, a file named <code>sd-on-eks-&lt;version&gt;.tgz</code> will be output. Place this file in an empty folder and run the following command:</p> <pre><code>helm repo index\n</code></pre> <p>You can place the generated archive and <code>index.yaml</code> on the HTTP server. Assuming the domain name of the HTTP server is <code>example.com</code> (IP address is also acceptable), you need to modify <code>config.yaml</code> and add the following content under each runtime that needs to use this Helm Chart:</p> <pre><code>modelsRuntime:\n- name: sdruntime\n  namespace: default\n  type: sdwebui\n  chartRepository: \"http://example.com/\"\n  chartVersion: \"1.0.0\" # Modify if you customize the Helm Chart version\n</code></pre>"},{"location":"implementation-guide/deployment/models/","title":"Model Storage","text":"<p>The models required for this solution should be pre-stored in an S3 bucket.</p>"},{"location":"implementation-guide/deployment/models/#create-a-bucket","title":"Create a Bucket","text":"<p>Please follow these steps to create a bucket:</p> AWS Management ConsoleAWS CLI <ul> <li>Open the Amazon S3 console.</li> <li>In the left navigation pane, choose Buckets.</li> <li>Choose Create Bucket.</li> <li>In Bucket name, enter a name for your bucket. The name must follow the bucket naming rules.</li> <li>In AWS Region, choose the same region where you plan to deploy the solution.</li> </ul> <p>Note</p> <p>Make sure the bucket is in the same AWS Region as your solution deployment. If you plan to deploy multiple copies of the solution across multiple regions, create a separate bucket in each region.</p> <ul> <li>Choose Create Bucket.</li> </ul> <p>Run the following command to create a bucket. Replace <code>&lt;bucket name&gt;</code> with the name you want to use for your bucket, and <code>us-east-1</code> with the AWS Region where you plan to deploy the solution: <pre><code>aws s3api create-bucket --bucket &lt;bucket name&gt; --region us-east-1\n</code></pre></p>"},{"location":"implementation-guide/deployment/models/#store-models","title":"Store Models","text":"<p>Please store all the models you need to use in the S3 bucket, with the following directory structure:</p> <pre><code>\u2514\u2500\u2500 /\n    \u251c\u2500\u2500 CLIP\n    \u251c\u2500\u2500 Codeformer\n    \u251c\u2500\u2500 ControlNet\n    \u251c\u2500\u2500 ESRGAN\n    \u251c\u2500\u2500 GFPGAN\n    \u251c\u2500\u2500 LDSR\n    \u251c\u2500\u2500 Lora\n    \u251c\u2500\u2500 RealESRGAN\n    \u251c\u2500\u2500 ScuNET\n    \u251c\u2500\u2500 Stable-diffusion\n    \u251c\u2500\u2500 SwinIR\n    \u251c\u2500\u2500 VAE\n    \u251c\u2500\u2500 VAE-approx\n    \u251c\u2500\u2500 embeddings\n    \u2514\u2500\u2500 hypernetworks\n</code></pre> <p>Please place the models in their corresponding directories. The <code>Stable-diffusion</code> directory must exist and contain the Stable Diffusion model. Other directories can be omitted if there are no models for them.</p> <p>Currently, models in <code>.safetensors</code> and <code>.ckpt</code> formats are supported. If the models you downloaded from Civitai do not have an extension, please add the <code>.ckpt</code> extension.</p> <p>Please follow these steps to upload the models to the S3 bucket:</p> AWS Management ConsoleAWS CLI <p>Note</p> <p>When uploading model files from mainland China to overseas, you may encounter slow upload speeds or connection interruptions. Since browser uploads do not support resuming from interruptions, it is not recommended to use the management console to upload models.</p> <ul> <li>Open the Amazon S3 console.</li> <li>In the left navigation pane, choose Buckets.</li> <li>Select the bucket you created in the previous step, and navigate to the desired folder.</li> <li>If the corresponding folder does not exist:<ul> <li>Choose Create Folder.</li> <li>In Folder Name, enter the folder name.</li> <li>Choose Create folder.</li> <li>Repeat the above steps until the folder structure matches the one above.</li> </ul> </li> <li>Choose Upload.</li> <li>Choose Add files, and select the model files you want to upload.</li> <li>Choose Upload. Do not close the browser during the upload process.</li> </ul> <p>Run the following command to upload the model files to the bucket. Replace <code>&lt;model name&gt;</code> with the name of your model file, <code>&lt;folder&gt;</code> with the model type, and <code>&lt;bucket name&gt;</code> with the name of your bucket: <pre><code>aws s3 cp &lt;model name&gt; s3://&lt;bucket name&gt;/&lt;folder&gt;/\n</code></pre></p> <p>Tip</p> <p>When using the AWS CLI for uploading, you do not need to create the directory structure beforehand.</p> <p>Tip</p> <p>You can use third-party tools like s5cmd to improve upload speed.</p>"},{"location":"implementation-guide/developer/api-spec/","title":"API Definition","text":"<p>We provide API definitions for <code>v1alpha1</code> and <code>v1alpha2</code> version requests. The definition is built on OpenAPI v3.</p> <p>You can get the corresponding API definitions in the <code>docs/api</code> directory of the source code.</p>"},{"location":"implementation-guide/developer/source/","title":"Source code","text":"<p>Visit our GitHub repository to download the source code for this solution. This solution template is generated using the AWS Cloud Development Kit (CDK). Please refer to the README.md file for more information.</p>"},{"location":"implementation-guide/observability/logging/","title":"View Logs","text":"<p>You can view the logs for this solution from CloudWatch Logs.</p> AWS Management Console <ul> <li>Open the Amazon CloudWatch console.</li> <li>In the left navigation pane, choose Logs - Log groups.</li> <li>Select the corresponding log group. The log group format is <code>/aws/eks/fluentbit-cloudwatch/workload/default</code>, replace <code>default</code> with the Kubernetes namespace where the workload is running.</li> <li>You can select the corresponding Log Stream to view logs for different components, or select Search all log streams to search within the logs.</li> </ul>"},{"location":"implementation-guide/observability/monitoring/","title":"View Monitoring","text":"<p>You can view the monitoring metrics for this solution from CloudWatch.</p> <p>The monitoring metrics are provided by Container Insight, please refer to Amazon EKS and Kubernetes Container Insights metrics to learn more about the metrics.</p> AWS Management Console <ul> <li>Open the Amazon CloudWatch console.</li> <li>In the left navigation pane, choose Metrics - All Metrics.</li> <li>Select ContainerInsights.</li> <li>Select ClusterName, Namespace, PodName</li> <li>You can view the metrics for different replicas based on PodName.</li> </ul>"},{"location":"implementation-guide/observability/tracing/","title":"View Traces","text":"<p>You can view the time spent on each stage of individual requests from X-Ray to achieve tracing.</p>"},{"location":"implementation-guide/observability/tracing/#service-overview","title":"Service Overview","text":"AWS Management Console <ul> <li>Open the Amazon CloudWatch console.</li> <li>In the left navigation pane, choose X-Ray traces - Service map.</li> <li>The service map will list the relevant components of this solution, and you can click on a component to display its metrics (including latency, request count, and error count).</li> </ul>"},{"location":"implementation-guide/observability/tracing/#view-request-details","title":"View Request Details","text":"<pre><code>* In the left navigation pane, choose **X-Ray traces** - **Traces**.\n* In the **Traces** section below, the details of each request will be listed, and you can select an individual request to display the detailed time spent on each step.\n</code></pre>"},{"location":"implementation-guide/operation/kubernetes-cluster/","title":"Kubernetes Cluster Management","text":"<p>You can use the <code>kubectl</code> command to connect to the cluster created by the solution, get the current system running status, and perform customizations.</p>"},{"location":"implementation-guide/operation/kubernetes-cluster/#install-kubectl","title":"Install kubectl","text":"<p>You can refer to the Installing or updating kubectl documentation to install the <code>kubectl</code> command-line tool. Please install kubectl compatible with Kubernetes 1.28.</p>"},{"location":"implementation-guide/operation/kubernetes-cluster/#log-in-to-the-kubernetes-cluster","title":"Log in to the Kubernetes Cluster","text":"<p>You can find the command to connect to the EKS cluster from the CloudFormation output:</p> AWS Management ConsoleAWS CLI <ul> <li>Go to the AWS CloudFormation Console</li> <li>Select Stacks</li> <li>In the list, select SdOnEKSStack (or your custom name)</li> <li>Select Output</li> <li>Record the value of the ConfigCommand item</li> <li>Execute the command in the terminal.</li> </ul> <p>Run the following command to get the command:</p> <pre><code>aws cloudformation describe-stacks --stack-name SdOnEKSStack --output text --query 'Stacks[0].Outputs[?OutputKey==`ConfigCommand`].OutputValue'\n</code></pre> <p>Execute the command in the terminal.</p>"},{"location":"implementation-guide/solution-overview/cost/","title":"Cost Estimation","text":"<p>Important</p> <p>The cost estimates described in this section are examples and may vary depending on your environment.</p> <p>You will incur costs for using various Amazon Web Services when running the solution. The main factors affecting the cost of the solution include:</p> <ul> <li>The instance type and purchasing option you choose</li> <li>The number of images generated</li> <li>The Elastic Scaling configuration</li> </ul> <p>Taking the text-to-image task with 512x512, steps=16 as an example, using the g5.xlarge instance in the AWS US East (N. Virginia) region, the average generation speed per image is about 1.5s/image. According to the Amazon Web Services official page, the on-demand pricing is $1.006/hour, and the average inference computing cost per thousand images is $0.42. If you choose a 1-year ISP ($0.604/hour), the average inference computing cost per thousand images is $0.25. If you choose a 3-year ISP ($0.402/hour), the average inference computing cost per thousand images can be as low as $0.17.</p> <p>In addition, other running costs of the solution include storage costs, on-demand costs for serverless services, and network data transfer costs. For detailed pricing formulas, please refer to the Pricing Calculator.</p>"},{"location":"implementation-guide/usage/","title":"Rules for API Calls","text":"<p>After deploying the solution, you can send requests to the Stable Diffusion runtime through the API endpoint of Amazon API Gateway.</p> <p>When sending requests, please follow these rules:</p>"},{"location":"implementation-guide/usage/#api-request-example","title":"API Request Example","text":"<p>You can use the test script to verify if the solution is deployed successfully. Run the following command to test:</p> <pre><code>cd test\nSTACK_NAME=sdoneksStack RUNTIME_TYPE=sdwebui ./run.sh\n</code></pre> <p>If you have modified the solution stack name or runtime type, please replace <code>sdoneksStack</code> and <code>sdwebui</code> with the corresponding content.</p> <p>The script will automatically find the API Gateway endpoint, obtain the API Key, and send a test request.</p> <ul> <li>For the SD Web UI runtime, it will send a text-to-image and an image-to-image request.</li> <li>For the ComfyUI runtime, it will send a Pipeline request.</li> </ul> <p>After a few seconds to a few minutes (depending on whether image caching is enabled and the minimum number of instance replicas), you can find the generated images at the <code>output_location</code>.</p>"},{"location":"implementation-guide/usage/#request-endpoint-and-format","title":"Request Endpoint and Format","text":"<p>The API endpoint of the solution can be obtained from the CloudFormation outputs:</p> AWS Management ConsoleAWS CLI <ul> <li>Go to the AWS CloudFormation Console</li> <li>Select Stacks</li> <li>In the list, select SdOnEKSStack (or your custom name)</li> <li>Select Output</li> <li>Record the value of the FrontApiEndpoint item (in the format of <code>https://abcdefghij.execute-api.ap-southeast-1.amazonaws.com/prod/</code>)</li> </ul> <p>Run the following command to get the API endpoint:</p> <pre><code>aws cloudformation describe-stacks --stack-name SdOnEKSStack --output text --query 'Stacks[0].Outputs[?OutputKey==`FrontApiEndpoint`].OutputValue'\n</code></pre> <p>You need to append the API version to the endpoint. Currently, we support <code>v1alpha1</code> and <code>v1alpha2</code> versions. When using the <code>v1alpha2</code> version API, the request should be sent to:</p> <pre><code>https://abcdefghij.execute-api.ap-southeast-1.amazonaws.com/prod/v1alpha2\n</code></pre> <p>This endpoint only accepts JSON-formatted POST requests, and the <code>Content-Type: application/json</code> request header is required.</p>"},{"location":"implementation-guide/usage/#request-types","title":"Request Types","text":"<p>Depending on the runtime type, each runtime only accepts specific types of requests:</p> <ul> <li>For the SD Web UI runtime, it only accepts text-to-image and image-to-image requests.</li> <li>For the ComfyUI runtime, it only accepts Pipeline requests.</li> </ul> <p>Please refer to the detailed documentation of each request type for the specific request format.</p>"},{"location":"implementation-guide/usage/#api-key","title":"API Key","text":"<p>For security reasons, all requests need to include an API Key. Follow these steps to obtain the API Key:</p> AWS Management ConsoleAWS CLI <ul> <li>Go to the Amazon API Gateway Console</li> <li>Select API Keys</li> <li>In the list, select the API Key with a name similar to <code>SdOnEK-defau-abcdefghij</code> (or your custom name)</li> <li>Record the value of the API key item</li> </ul> <p>Run the following command to get the API Key:</p> <pre><code>echo $(aws cloudformation describe-stacks --stack-name SdOnEKSStack --output text --query 'Stacks[0].Outputs[?OutputKey==`GetAPIKeyCommand`].OutputValue')\n</code></pre> <p>When sending requests, you need to include the <code>x-api-key</code> request header, with its value being the API Key obtained above.</p> <p>Unauthenticated Requests</p> <p>Requests without an API Key will directly return a <code>401</code> error.</p>"},{"location":"implementation-guide/usage/#throttling-rules","title":"Throttling Rules","text":"<p>To protect the backend API, API Gateway will throttle excessive requests sent using the same API Key.</p> <p>The default settings are:</p> <ul> <li>30 requests per second</li> <li>Burst of 50 requests</li> </ul> <p>For detailed information about throttling principles, please refer to Throttle API requests for better throughput</p> <p>If you need to modify these settings, please change the relevant content in the <code>APIGW</code> section of the <code>config.yaml</code> file. You can also modify the corresponding Usage Plan in API Gateway.</p>"},{"location":"implementation-guide/usage/#next-steps","title":"Next Steps","text":"<p>According to the different usage methods in the right-hand directory, send requests to Stable Diffusion.</p>"},{"location":"implementation-guide/usage/callback/","title":"Callbacks and Notifications","text":"<p>The Stable Diffusion on Amazon EKS solution adopts an asynchronous inference mode. After an image is generated or an error occurs, users will be notified via Amazon SNS. User applications can subscribe to the SNS topic to receive notifications when image generation is completed.</p>"},{"location":"implementation-guide/usage/callback/#adding-subscriptions","title":"Adding Subscriptions","text":"<p>Please refer to the Amazon SNS documentation to learn about the types of message destinations supported by SNS.</p> <p>You can find the ARN of the generated SNS topic from the CloudFormation outputs:</p> AWS Management ConsoleAWS CLI <ul> <li>Go to the AWS CloudFormation Console</li> <li>Select Stacks</li> <li>In the list, select SdOnEKSStack (or your custom name)</li> <li>Select Output</li> <li>Record the value of the sdNotificationOutputArn item (in the format <code>arn:aws:sns:us-east-1:123456789012:SdOnEKSStack-sdNotificationOutputCfn-abcdefgh</code>)</li> </ul> <p>Run the following command to get the SNS topic ARN:</p> <pre><code>aws cloudformation describe-stacks --stack-name SdOnEKSStack --output text --query 'Stacks[0].Outputs[?OutputKey==`sdNotificationOutputArn`].OutputValue'\n</code></pre> <p>To receive messages, you need to add your message receiver (such as an Amazon SQS queue, HTTP endpoint, etc.) as a subscription to the SNS topic.</p> AWS Management ConsoleAWS CLI <ul> <li>In the left navigation pane, select Subscriptions.</li> <li>On the Subscriptions page, select Create subscription.</li> <li>In the Details section of the Create subscription page, do the following:<ul> <li>For Topic ARN, select the ARN you recorded in the previous step.</li> <li>For Protocol, select the type of your receiver.</li> <li>For Endpoint, enter the address of your receiver, such as an email address or the ARN of an Amazon SQS queue.</li> </ul> </li> <li>Select Create subscription</li> </ul> <p>Please refer to Use Amazon SNS with the AWS CLI to add a subscription to the topic.</p>"},{"location":"implementation-guide/usage/callback/#callback-message-format","title":"Callback Message Format","text":"<p>The solution will send task completion notifications to SNS in the following format, regardless of the API version used in the request:</p> <pre><code>{\n    \"id\": \"task_id\", // Task ID\n    \"result\": true, // true for successful completion, false for unsuccessful completion\n    \"image_url\": [ // S3 URLs of the generated images, in the format task_id+4_random_digits+image_number, all image links will be included if there are multiple images\n        \"s3://outputbucket/output/test-t2i/test-t2i-abcd-1.png\"\n    ],\n    \"output_url\": \"s3://outputbucket/output/test-t2i/test-t2i-abcd.out\", // S3 URL of the task output, containing the full output during runtime\n    \"context\": { // Context content attached in the request\n        \"abc\": 123\n    }\n}\n</code></pre>"},{"location":"implementation-guide/usage/controlnet/","title":"ControlNet Plugin","text":""},{"location":"implementation-guide/usage/controlnet/#request-format","title":"Request Format","text":"<pre><code>{\n    \"alwayson_scripts\": {\n        // Required, task type\n        \"task\": \"text-to-image\",\n        // Required, task ID, used for uploading result images and returning responses\n        \"id_task\": \"40521\",\n        // Required, base model name, associated with queue distribution or model switching\n        \"sd_model_checkpoint\": \"v1-5-pruned-emaonly.safetensors\",\n        // Optional, user ID\n        \"uid\": \"123\",\n        // Optional, ControlNet parameters\n        \"controlnet\": {\n            \"args\": [\n                {\n                    \"image_link\": \"https://tse3-mm.cn.bing.net/th/id/OIP-C.2Z9l9li7mrfDThPW3_LE5wHaLG?pid=ImgDet&amp;rs=1\",\n                    \"module\": \"openpose\",\n                    \"model\": \"control_v11p_sd15_openpose\",\n                    \"enabled\": true,\n                    \"weight\": 1,\n                    \"resize_mode\": \"Crop and Resize\"\n                },\n                {\n                    \"image_link\": \"https://tse3-mm.cn.bing.net/th/id/OIP-C.2Z9l9li7mrfDThPW3_LE5wHaLG?pid=ImgDet&amp;rs=1\",\n                    \"module\": \"depth_leres\",\n                    \"model\": \"control_v11f1p_sd15_depth\",\n                    \"enabled\": true,\n                    \"weight\": 0.8,\n                    \"resize_mode\": \"Crop and Resize\"\n                }\n            ]\n        }\n    },\n    // All following are official parameters, use default values or pass them directly\n    \"prompt\": \"Best Quality, 1boy, wear golden LeoArmor, solo, short brown hair, looking at viewer\",\n    \"negative_prompt\": \"nsfw\",\n    \"sampler_index\": \"DPM++ SDE Karras\",\n    \"batch_size\": 1,\n    \"steps\": 16,\n    \"cfg_scale\": 7,\n    \"n_iter\": 3,\n    \"width\": 512,\n    \"height\": 512,\n    \"seed\": -1\n}\n</code></pre>"},{"location":"implementation-guide/usage/extra-single-image/","title":"Single Image Super-Resolution Upscaling (SD Web UI)","text":"<p>Info</p> <p>This request type is only applicable to SD Web UI runtime.</p> <p>This request type only provides the <code>v1alpha2</code> API.</p> <p>For a single image, use the super-resolution model to upscale the image.</p>"},{"location":"implementation-guide/usage/extra-single-image/#request-format","title":"Request Format","text":"v1alpha2 <pre><code>{\n  \"task\": {\n    \"metadata\": {\n      \"id\": \"test-extra\",\n      \"runtime\": \"sdruntime\",\n      \"tasktype\": \"extra-single-image\",\n      \"prefix\": \"output\",\n      \"context\": \"\"\n    },\n    \"content\": {\n      \"resize_mode\":0,\n      \"show_extras_results\":false,\n      \"gfpgan_visibility\":0,\n      \"codeformer_visibility\":0,\n      \"codeformer_weight\":0,\n      \"upscaling_resize\":4,\n      \"upscaling_resize_w\":512,\n      \"upscaling_resize_h\":512,\n      \"upscaling_crop\":false,\n      \"upscaler_1\":\"R-ESRGAN 4x+\",\n      \"upscaler_2\":\"None\",\n      \"extras_upscaler_2_visibility\":0,\n      \"upscale_first\":false,\n      \"image\":\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/cat.png\"\n    }\n  }\n}\n</code></pre>"},{"location":"implementation-guide/usage/extra-single-image/#response-format","title":"Response Format","text":"v1alpha2 <pre><code>{\n  \"id_task\": \"test-extra\",\n  \"runtime\": \"sdruntime\",\n  \"output_location\": \"s3://outputbucket/output/test-t2i\"\n}\n</code></pre>"},{"location":"implementation-guide/usage/extra-single-image/#available-super-resolution-models","title":"Available Super-Resolution Models","text":"<p>The available super-resolution models are the same as the default models in SD Web UI:</p> <ul> <li>Lanczos</li> <li>Nearest</li> <li>4x-UltraSharp</li> <li>ESRGAN_4X</li> <li>LDSR</li> <li>R-ESRGAN 4x+</li> <li>R-ESRGAN 4x+ Anime6B</li> <li>ScuNET GAN</li> <li>ScuNET PSNR</li> <li>SwinIR 4x</li> </ul> <p>If you need more super-resolution models, you can place them in the <code>LDSR</code>, <code>SwinIR</code>, <code>ESRGAN</code>, <code>RealESRGAN</code>, <code>ScuNET</code> directories in the S3 bucket according to the model type.</p> <p>After that, you need to restart the Pod for the new models to take effect.</p>"},{"location":"implementation-guide/usage/extra-single-image/#image-retrieval","title":"Image Retrieval","text":"<p>After the image is generated, it will be stored in the S3 bucket path specified by <code>output_location</code>. The default storage format is lossless PNG, but if special formats (such as GIF) are involved, the system will automatically recognize and add the extension.</p>"},{"location":"implementation-guide/usage/image-to-image/","title":"Image-to-Image (SD Web UI)","text":"<p>Info</p> <p>This request type is only applicable to the SD Web UI runtime.</p> <p>The basic usage of Stable Diffusion is to input a prompt and a reference image, and it can generate an image similar to the reference image.</p> <p>The content in the request will be passed directly to the SD Web UI, but if there are links (HTTP or S3 URL), the content of the links will be converted to base64 encoded content and filled in the corresponding items.</p>"},{"location":"implementation-guide/usage/image-to-image/#request-format","title":"Request Format","text":"v1alpha2v1alpha1 <pre><code>{\n  \"task\": {\n    \"metadata\": {\n      \"id\": \"test-i2i\", // Required, task ID\n      \"runtime\": \"sdruntime\", // Required, runtime name used by the task\n      \"tasktype\": \"image-to-image\", // Required, task type\n      \"prefix\": \"output\", // Required, prefix (directory name) of output files in the S3 bucket\n      \"context\": \"\" // Optional, can contain any information, will be included in the callback\n    },\n    \"content\": { // Same specification as the SD Web UI image-to-image interface\n      \"alwayson_scripts\": {},\n      \"prompt\": \"cat wizard, gandalf, lord of the rings, detailed, fantasy, cute, adorable, Pixar, Disney, 8k\",\n      \"steps\": 16,\n      \"width\": 512,\n      \"height\": 512,\n      \"init_images\": [\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/cat.png\"] // Place image links here, images will be downloaded, base64 encoded and put into the request\n    }\n  }\n}\n</code></pre> <pre><code>{\n    \"alwayson_scripts\": {\n        \"task\": \"image-to-image\", // Required, task type\n        \"image_link\": \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/cat.png\", // Required, URL of the input image\n        \"id_task\": \"test-i2i\", // Required, task ID, will be used when uploading result images and returning responses\n        \"sd_model_checkpoint\": \"v1-5-pruned-emaonly.safetensors\", // Required, base model name, associated with queue distribution or model switching\n    },\n    // The following are official parameters, use the default values or pass them in directly\n    \"prompt\": \"cat wizard, gandalf, lord of the rings, detailed, fantasy, cute, adorable, Pixar, Disney, 8k\",\n    \"steps\": 16,\n    \"width\": 512,\n    \"height\": 512\n}\n</code></pre>"},{"location":"implementation-guide/usage/image-to-image/#response-format","title":"Response Format","text":"v1alpha2v1alpha1 <pre><code>{\n  \"id_task\": \"test-i2i\",\n  \"runtime\": \"sdruntime\",\n  \"output_location\": \"s3://outputbucket/output/test-t2i\"\n}\n</code></pre> <pre><code>{\n  \"id_task\": \"test-i2i\",\n  \"sd_model_checkpoint\": \"v1-5-pruned-emaonly.safetensors\",\n  \"output_location\": \"s3://outputbucket/output/test-t2i\"\n}\n</code></pre>"},{"location":"implementation-guide/usage/image-to-image/#model-switching","title":"Model Switching","text":"<p>If the corresponding runtime has <code>dynamicModel: true</code> set, you need to add the following content to the <code>alwayson_scripts</code> in the request:</p> <pre><code>        \"content\": {\n          \"alwayson_scripts\": {\n            \"sd_model_checkpoint\": \"v1-5-pruned-emaonly.safetensors\" //Place the model name here\n          },\n        }\n</code></pre> <p>After receiving the request, the SD Web UI will unload the current model and load the corresponding model from memory/S3 bucket. If the specified model does not exist, the request will return an error directly.</p>"},{"location":"implementation-guide/usage/image-to-image/#image-retrieval","title":"Image Retrieval","text":"<p>After the image generation is completed, it will be stored in the S3 bucket path specified by <code>output_location</code>. If <code>batch_size</code> or other parameters for generating multiple images are set, each image will be automatically numbered and stored.</p> <p>The default storage format is lossless PNG, but if special formats (such as GIF) are involved, the system will automatically recognize and add the extension.</p>"},{"location":"implementation-guide/usage/lora/","title":"LoRA Fine-Tuning","text":"<p>LoRA can be directly incorporated into the prompt using <code>&lt;lora:[name]:[version]&gt;</code>.</p>"},{"location":"implementation-guide/usage/lora/#request-format","title":"Request Format","text":"<pre><code>{\n    \"alwayson_scripts\": {\n        // Required, task type\n        \"task\": \"text-to-image\",\n        // Required, task ID, used for uploading result images and returning responses\n        \"id_task\": \"40521\",\n        // Required, base model name, associated with queue distribution or model switching\n        \"sd_model_checkpoint\": \"v1-5-pruned-emaonly.safetensors\",\n        // Optional, user ID\n        \"uid\": \"123\",\n    },\n    // All following are official parameters, use default values or pass them directly\n    \"prompt\": \"&lt;lora:LeoArmor:0.9&gt;, Best Quality, 1boy, wear golden LeoArmor, solo, short brown hair, looking at viewer\",\n    \"negative_prompt\": \"nsfw\",\n    \"sampler_index\": \"DPM++ SDE Karras\",\n    \"batch_size\": 1,\n    \"steps\": 16,\n    \"cfg_scale\": 7,\n    \"n_iter\": 3,\n    \"width\": 512,\n    \"height\": 512,\n    \"seed\": -1\n}\n</code></pre>"},{"location":"implementation-guide/usage/pipeline/","title":"Pipeline (ComfyUI)","text":"<p>Info</p> <p>This request type is only applicable to the ComfyUI runtime.</p> <p>This request type only provides the <code>v1alpha2</code> API.</p> <p>ComfyUI provides workflow orchestration capabilities, allowing you to orchestrate workflows using various nodes in the interface and export them to a <code>json</code> file.</p>"},{"location":"implementation-guide/usage/pipeline/#export-workflow","title":"Export Workflow","text":"<p>After designing the workflow in the interface, follow these steps to export it:</p> <ul> <li>Select the gear icon in the top right corner of the menu panel</li> <li>Select <code>Enable Dev mode Options</code></li> <li>Select <code>Save(API Format)</code> to save the workflow as a file.</li> </ul>"},{"location":"implementation-guide/usage/pipeline/#request-format","title":"Request Format","text":"v1alpha2 <pre><code>{\n  \"task\": {\n    \"metadata\": {\n      \"id\": \"test-pipeline\", // Required, task ID\n      \"runtime\": \"sdruntime\", // Required, runtime name used by the task\n      \"tasktype\": \"pipeline\", // Required, task type\n      \"prefix\": \"output\", // Required, prefix (directory name) for output files in the S3 bucket\n      \"context\": \"\" // Optional, can contain any information, will be included in the callback\n    },\n    \"content\": {\n      ... // Insert the exported workflow content here\n    }\n}\n}\n</code></pre>"},{"location":"implementation-guide/usage/pipeline/#response-format","title":"Response Format","text":"v1alpha2 <pre><code>{\n  \"id_task\": \"test-pipeline\",\n  \"runtime\": \"sdruntime\",\n  \"output_location\": \"s3://outputbucket/output/test-pipeline\"\n}\n</code></pre>"},{"location":"implementation-guide/usage/pipeline/#image-retrieval","title":"Image Retrieval","text":"<p>After the image generation is complete, the images will be stored in the S3 bucket path specified by <code>output_location</code>. If <code>batch_size</code> or other parameters for generating multiple images are set, each image will be automatically numbered and stored.</p> <p>The default storage format is lossless PNG, but if special formats (such as GIF) are involved, the system will automatically recognize and add the appropriate extension.</p>"},{"location":"implementation-guide/usage/text-to-image/","title":"Text-to-Image (SD Web UI)","text":"<p>Info</p> <p>This request type is only applicable to SD Web UI runtime.</p> <p>The most basic usage of Stable Diffusion is to input a prompt and generate a corresponding image.</p> <p>The content in the request will be passed directly to SD Web UI, but if there are links (HTTP or S3 URL), the content of the links will be converted to base64 encoded content and filled in the corresponding fields.</p>"},{"location":"implementation-guide/usage/text-to-image/#request-format","title":"Request Format","text":"v1alpha2v1alpha1 <pre><code>{\n  \"task\": {\n    \"metadata\": {\n      \"id\": \"test-t2i\", // Required, task ID\n      \"runtime\": \"sdruntime\", // Required, runtime name used for the task\n      \"tasktype\": \"text-to-image\", // Required, task type\n      \"prefix\": \"output\", // Required, prefix (directory name) of output files in S3 bucket\n      \"context\": \"\" // Optional, can contain any information, will be included in the callback\n    },\n    \"content\": { // Same specification as SD Web UI text-to-image interface\n      \"alwayson_scripts\": {},\n      \"prompt\": \"A dog\",\n      \"steps\": 16,\n      \"width\": 512,\n      \"height\": 512\n    }\n  }\n}\n</code></pre> <pre><code>{\n    \"alwayson_scripts\": {\n        \"task\": \"text-to-image\", // Required, task type\n        \"sd_model_checkpoint\": \"v1-5-pruned-emaonly.safetensors\", // Required, base model name, associated with queue distribution or model switching\n        \"id_task\": \"test-t2i\", // Required, task ID, will be used when uploading result images and returning responses\n        \"save_dir\": \"outputs\" // Required, prefix (directory name) of output files in S3 bucket\n    },\n    // The following are official parameters, use default values or pass them directly\n    \"prompt\": \"A dog\",\n    \"steps\": 16,\n    \"width\": 512,\n    \"height\": 512\n}\n</code></pre>"},{"location":"implementation-guide/usage/text-to-image/#response-format","title":"Response Format","text":"v1alpha2v1alpha1 <pre><code>{\n  \"id_task\": \"test-t2i\",\n  \"runtime\": \"sdruntime\",\n  \"output_location\": \"s3://outputbucket/output/test-t2i\"\n}\n</code></pre> <pre><code>{\n  \"id_task\": \"test-t2i\",\n  \"sd_model_checkpoint\": \"v1-5-pruned-emaonly.safetensors\",\n  \"output_location\": \"s3://outputbucket/output/test-t2i\"\n}\n</code></pre>"},{"location":"implementation-guide/usage/text-to-image/#model-switching","title":"Model Switching","text":"<p>If the corresponding runtime has <code>dynamicModel: true</code> set, you need to add the following content in the <code>alwayson_scripts</code> of the request:</p> <pre><code>        \"content\": {\n          \"alwayson_scripts\": {\n            \"sd_model_checkpoint\": \"v1-5-pruned-emaonly.safetensors\" //Put the model name here\n          },\n        }\n</code></pre> <p>After receiving the request, SD Web UI will unload the current model and load the corresponding model from memory/S3 bucket. If the specified model does not exist, the request will directly return an error.</p>"},{"location":"implementation-guide/usage/text-to-image/#image-retrieval","title":"Image Retrieval","text":"<p>After the image generation is completed, it will be stored in the S3 bucket path specified by <code>output_location</code>. If <code>batch_size</code> or other parameters for generating multiple images are set, each image will be automatically numbered and stored.</p> <p>The default storage format is lossless PNG, but if special formats (such as GIF) are involved, the system will automatically recognize and add the extension.</p>"}]}